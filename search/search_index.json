{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Medium Converter","text":"<ul> <li> <p>[:material-book-outline:]{.lg .middle} Simple to use   Convert Medium articles to various formats with minimal configuration</p> </li> <li> <p>[:material-text-box-outline:]{.lg .middle} Multiple formats   Export to Markdown, PDF, HTML, EPUB, LaTeX, and DOCX</p> </li> <li> <p>[:material-robot-outline:]{.lg .middle} LLM enhancement   Improve article text with AI-powered grammar and clarity improvements</p> </li> <li> <p>[:material-lock-open-outline:]{.lg .middle} Paywall access   Use your browser cookies to access articles behind the paywall </p> </li> </ul>"},{"location":"#overview","title":"Overview","text":"<p>Medium Converter is a Python package that allows you to download Medium articles and convert them to various formats. It's designed to be easy to use while offering powerful features for advanced users.</p> <pre><code>import asyncio\nfrom medium_converter import convert_article\n\nasync def main():\n    await convert_article(\n        url=\"https://medium.com/example-article\",\n        output_format=\"markdown\",\n        output_path=\"article.md\",\n        enhance=True  # Use LLM enhancement\n    )\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>:material-file-multiple-outline: Multiple export formats: Convert to Markdown, PDF, HTML, EPUB, LaTeX, and DOCX</li> <li>:material-robot-outline: LLM enhancement: Improve clarity and fix grammar with AI</li> <li>:material-lock-open-outline: Paywall access: Use your browser cookies to access articles behind the paywall</li> <li>:material-lightning-bolt-outline: Async processing: Convert multiple articles in parallel</li> <li>:material-laptop-outline: Cross-platform: Works on Windows, macOS, and Linux</li> </ul>"},{"location":"#installation","title":"Installation","text":"<pre><code>pip install medium-converter\n</code></pre> <p>For additional features:</p> <pre><code># For PDF export\npip install medium-converter[pdf]\n\n# For LLM enhancement with OpenAI\npip install medium-converter[llm,openai]\n\n# For all features\npip install medium-converter[all]\n</code></pre>"},{"location":"#command-line-interface","title":"Command Line Interface","text":"<p>Medium Converter provides a beautiful command-line interface with emojis and colors:</p> <pre><code># Basic conversion\nmedium convert https://medium.com/example-article\n\n# Convert to PDF with enhancement\nmedium convert https://medium.com/example-article -f pdf --enhance\n\n# Batch processing\nmedium batch articles.txt -d ./output-dir\n</code></pre>"},{"location":"#quick-links","title":"Quick Links","text":"<ul> <li>Installation guide</li> <li>Quick start</li> <li>CLI usage</li> <li>Python API</li> <li>GitHub repository</li> </ul>"},{"location":"#license","title":"License","text":"<p>Medium Converter is released under the MIT License.</p>"},{"location":"advanced/batch-processing/","title":"Batch Processing","text":"<p>Medium Converter provides powerful batch processing capabilities to convert multiple articles at once.</p>"},{"location":"advanced/batch-processing/#command-line-interface","title":"Command Line Interface","text":""},{"location":"advanced/batch-processing/#basic-batch-processing","title":"Basic Batch Processing","text":"<p>Create a text file with Medium URLs, one per line:</p> <pre><code>https://medium.com/article1\nhttps://medium.com/article2\nhttps://medium.com/article3\n</code></pre> <p>Then run the batch command:</p> <pre><code>medium batch articles.txt -f markdown -d ./output-directory\n</code></pre>"},{"location":"advanced/batch-processing/#batch-options","title":"Batch Options","text":"<pre><code>medium batch articles.txt \\\n  --format pdf \\\n  --output-dir ./articles \\\n  --concurrent 5 \\\n  --enhance \\\n  --llm-provider openai\n</code></pre> Option Description Default <code>--format</code>, <code>-f</code> Output format <code>markdown</code> <code>--output-dir</code>, <code>-d</code> Output directory Required <code>--concurrent</code>, <code>-c</code> Maximum concurrent downloads <code>3</code> <code>--enhance</code> Use LLM to enhance content <code>False</code> <code>--no-enhance</code> Disable LLM enhancement Default <code>--use-cookies</code> Use browser cookies for auth <code>True</code> <code>--no-cookies</code> Disable browser cookie fetching <code>False</code> <code>--llm-provider</code> LLM provider to use Default from config <code>--verbose</code>, <code>-v</code> Enable verbose output <code>False</code> <code>--quiet</code>, <code>-q</code> Suppress non-error output <code>False</code>"},{"location":"advanced/batch-processing/#python-api","title":"Python API","text":""},{"location":"advanced/batch-processing/#async-batch-processing","title":"Async Batch Processing","text":"<pre><code>import asyncio\nfrom medium_converter import batch_convert\n\nasync def main():\n    urls = [\n        \"https://medium.com/article1\",\n        \"https://medium.com/article2\",\n        \"https://medium.com/article3\",\n    ]\n\n    results = await batch_convert(\n        urls=urls,\n        output_format=\"markdown\",\n        output_dir=\"./articles\",\n        enhance=True,\n        max_concurrent=5\n    )\n\n    # Results contains information about each conversion\n    for result in results:\n        print(f\"Converted: {result['url']} \u2192 {result['output_path']}\")\n        if result['error']:\n            print(f\"  Error: {result['error']}\")\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"advanced/batch-processing/#synchronous-batch-processing","title":"Synchronous Batch Processing","text":"<pre><code>from medium_converter import batch_convert_sync\n\nurls = [\n    \"https://medium.com/article1\",\n    \"https://medium.com/article2\",\n    \"https://medium.com/article3\",\n]\n\nresults = batch_convert_sync(\n    urls=urls,\n    output_format=\"pdf\",\n    output_dir=\"./articles\",\n    enhance=False,\n    max_concurrent=3\n)\n\nfor result in results:\n    print(f\"Converted: {result['url']} \u2192 {result['output_path']}\")\n</code></pre>"},{"location":"advanced/batch-processing/#working-with-csv-files","title":"Working with CSV Files","text":"<p>You can process lists of articles from CSV files:</p> <pre><code>import csv\nimport asyncio\nfrom medium_converter import batch_convert\n\nasync def process_csv(csv_file):\n    # Read URLs from CSV\n    urls = []\n    with open(csv_file, 'r') as f:\n        reader = csv.DictReader(f)\n        for row in reader:\n            urls.append(row['url'])\n\n    # Process the URLs\n    await batch_convert(\n        urls=urls,\n        output_format=\"markdown\",\n        output_dir=\"./articles\"\n    )\n\nif __name__ == \"__main__\":\n    asyncio.run(process_csv(\"articles.csv\"))\n</code></pre>"},{"location":"advanced/batch-processing/#error-handling","title":"Error Handling","text":"<p>Batch processing continues even if some articles fail. Errors are captured in the results:</p> <pre><code>import asyncio\nfrom medium_converter import batch_convert\n\nasync def main():\n    urls = [\n        \"https://medium.com/article1\",\n        \"https://invalid-url\",  # This will fail\n        \"https://medium.com/article3\",\n    ]\n\n    results = await batch_convert(\n        urls=urls,\n        output_format=\"markdown\",\n        output_dir=\"./articles\"\n    )\n\n    # Process results and handle errors\n    successful = [r for r in results if not r['error']]\n    failed = [r for r in results if r['error']]\n\n    print(f\"Successfully converted: {len(successful)} articles\")\n    print(f\"Failed to convert: {len(failed)} articles\")\n\n    for result in failed:\n        print(f\"Failed to convert {result['url']}: {result['error']}\")\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"advanced/batch-processing/#performance-optimization","title":"Performance Optimization","text":""},{"location":"advanced/batch-processing/#concurrency-control","title":"Concurrency Control","text":"<p>The <code>max_concurrent</code> parameter controls how many articles are processed simultaneously. This should be balanced based on your system resources:</p> <ul> <li>CPU-bound tasks (like LLM enhancement): use fewer concurrent tasks (1-2 per CPU core)</li> <li>I/O-bound tasks (like downloading): use more concurrent tasks (10-20 is often reasonable)</li> </ul> <pre><code># Optimize for CPU-bound tasks (with LLM enhancement)\nawait batch_convert(\n    urls=urls,\n    enhance=True,\n    max_concurrent=4  # Good for a quad-core system\n)\n\n# Optimize for I/O-bound tasks (without LLM enhancement)\nawait batch_convert(\n    urls=urls,\n    enhance=False,\n    max_concurrent=15  # Higher concurrency for network-bound tasks\n)\n</code></pre>"},{"location":"advanced/batch-processing/#progress-tracking","title":"Progress Tracking","text":"<p>For long-running batch jobs, you can track progress:</p> <pre><code>import asyncio\nfrom medium_converter import batch_convert\nfrom tqdm import tqdm  # For progress bars\n\nasync def main():\n    urls = [f\"https://medium.com/article{i}\" for i in range(1, 101)]  # 100 URLs\n\n    # Create a progress callback\n    progress_bar = tqdm(total=len(urls))\n\n    def progress_callback(url, status):\n        progress_bar.update(1)\n        progress_bar.set_description(f\"Processed: {url}\")\n\n    results = await batch_convert(\n        urls=urls,\n        output_format=\"markdown\",\n        output_dir=\"./articles\",\n        progress_callback=progress_callback\n    )\n\n    progress_bar.close()\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"advanced/batch-processing/#advanced-use-cases","title":"Advanced Use Cases","text":""},{"location":"advanced/batch-processing/#custom-naming","title":"Custom Naming","text":"<p>You can customize how output files are named:</p> <pre><code>import os\nimport asyncio\nfrom medium_converter import batch_convert\n\ndef custom_filename_generator(url, article):\n    # Use the article date and title for the filename\n    date_str = article.date.strftime(\"%Y-%m-%d\") if hasattr(article.date, \"strftime\") else article.date\n    safe_title = article.title.replace(\" \", \"_\").replace(\"/\", \"-\")[:50]  # First 50 chars\n    return f\"{date_str}_{safe_title}.md\"\n\nasync def main():\n    urls = [\n        \"https://medium.com/article1\",\n        \"https://medium.com/article2\",\n    ]\n\n    await batch_convert(\n        urls=urls,\n        output_format=\"markdown\",\n        output_dir=\"./articles\",\n        filename_generator=custom_filename_generator\n    )\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"advanced/batch-processing/#batch-processing-with-different-options-per-url","title":"Batch Processing with Different Options per URL","text":"<p>For more flexibility, you can use the low-level API to customize options per URL:</p> <pre><code>import asyncio\nfrom medium_converter import convert_article\nfrom medium_converter.llm.config import LLMConfig, LLMProvider\n\nasync def process_url(url, options):\n    try:\n        await convert_article(\n            url=url,\n            output_format=options[\"format\"],\n            output_path=options[\"output_path\"],\n            enhance=options[\"enhance\"],\n            llm_config=options.get(\"llm_config\")\n        )\n        return {\"url\": url, \"success\": True, \"output_path\": options[\"output_path\"]}\n    except Exception as e:\n        return {\"url\": url, \"success\": False, \"error\": str(e)}\n\nasync def main():\n    # Different options for each URL\n    urls_with_options = [\n        {\n            \"url\": \"https://medium.com/article1\",\n            \"format\": \"markdown\",\n            \"output_path\": \"./articles/article1.md\",\n            \"enhance\": False\n        },\n        {\n            \"url\": \"https://medium.com/article2\",\n            \"format\": \"pdf\",\n            \"output_path\": \"./articles/article2.pdf\",\n            \"enhance\": True,\n            \"llm_config\": LLMConfig(provider=LLMProvider.OPENAI)\n        },\n    ]\n\n    # Process concurrently (up to 3 at a time)\n    semaphore = asyncio.Semaphore(3)\n\n    async def bounded_process(url_options):\n        async with semaphore:\n            return await process_url(url_options[\"url\"], url_options)\n\n    tasks = [bounded_process(opt) for opt in urls_with_options]\n    results = await asyncio.gather(*tasks)\n\n    return results\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre> <p>This approach gives you complete control over how each URL is processed while still benefiting from concurrent execution.</p>"},{"location":"advanced/performance/","title":"Performance Optimization","text":"<p>This guide provides tips and strategies for optimizing the performance of Medium Converter.</p>"},{"location":"advanced/performance/#general-performance-tips","title":"General Performance Tips","text":""},{"location":"advanced/performance/#hardware-considerations","title":"Hardware Considerations","text":"<ul> <li>CPU: Multi-core processors help with parallel processing</li> <li>Memory: 8GB+ recommended, especially for PDF generation and LLM enhancement</li> <li>Disk: SSD improves file I/O performance</li> <li>Network: Stable internet connection required for fetching articles</li> </ul>"},{"location":"advanced/performance/#software-considerations","title":"Software Considerations","text":"<ul> <li>Python Version: Python 3.11+ offers better performance than older versions</li> <li>Dependencies: Keep dependencies updated for performance improvements</li> <li>Virtual Environment: Use a dedicated virtual environment for consistent performance</li> </ul>"},{"location":"advanced/performance/#optimizing-article-fetching","title":"Optimizing Article Fetching","text":""},{"location":"advanced/performance/#http-client-configuration","title":"HTTP Client Configuration","text":"<pre><code>from medium_converter.core.fetcher import fetch_article\n\n# Configure HTTP client for better performance\nawait fetch_article(\n    url=\"https://medium.com/example\",\n    http_options={\n        \"timeout\": 30,  # Increase timeout for slow connections\n        \"follow_redirects\": True,\n        \"http2\": True,  # Enable HTTP/2 for better performance\n        \"limits\": {\n            \"max_connections\": 10,\n            \"max_keepalive_connections\": 5,\n            \"keepalive_expiry\": 60.0  # seconds\n        }\n    }\n)\n</code></pre>"},{"location":"advanced/performance/#caching","title":"Caching","text":"<p>Enable caching to avoid refetching the same articles:</p> <pre><code>from medium_converter import convert_article\n\n# Enable caching\nawait convert_article(\n    url=\"https://medium.com/example\",\n    cache_options={\n        \"enable\": True,\n        \"ttl\": 86400,  # Cache for 24 hours\n        \"cache_dir\": \"~/.medium-converter/cache\"\n    }\n)\n</code></pre>"},{"location":"advanced/performance/#optimizing-export-process","title":"Optimizing Export Process","text":""},{"location":"advanced/performance/#format-specific-optimizations","title":"Format-Specific Optimizations","text":""},{"location":"advanced/performance/#pdf-optimization","title":"PDF Optimization","text":"<pre><code>await convert_article(\n    url=\"https://medium.com/example\",\n    output_format=\"pdf\",\n    export_options={\n        \"compress_images\": True,  # Optimize image size\n        \"defer_images\": True,  # Defer image loading for faster initial processing\n        \"optimize_for\": \"size\"  # Options: \"size\", \"quality\", \"speed\"\n    }\n)\n</code></pre>"},{"location":"advanced/performance/#markdown-optimization","title":"Markdown Optimization","text":"<pre><code>await convert_article(\n    url=\"https://medium.com/example\",\n    output_format=\"markdown\",\n    export_options={\n        \"lazy_image_loading\": True,  # Use lazy loading for images\n        \"minimize_whitespace\": True,  # Reduce file size\n        \"skip_metadata\": True  # Skip frontmatter for faster processing\n    }\n)\n</code></pre>"},{"location":"advanced/performance/#llm-enhancement-optimization","title":"LLM Enhancement Optimization","text":""},{"location":"advanced/performance/#model-selection","title":"Model Selection","text":"<p>Different models offer different performance characteristics:</p> Model Processing Speed Quality Token Limit GPT-3.5-Turbo Fast Good 4K-16K GPT-4 Slow Excellent 8K-32K Claude 3 Haiku Very Fast Good 200K Claude 3 Sonnet Medium Very Good 200K Claude 3 Opus Slow Excellent 200K Mistral Medium Fast Good 32K Local 7B Model Varies Good Varies"},{"location":"advanced/performance/#chunking-and-batching","title":"Chunking and Batching","text":"<p>For large articles, process content in chunks:</p> <pre><code>from medium_converter.llm.enhancer import enhance_article\nfrom medium_converter.llm.config import LLMConfig\n\nllm_config = LLMConfig(\n    # Provider settings\n    chunking={\n        \"enable\": True,\n        \"max_chunk_size\": 1000,  # Characters per chunk\n        \"overlap\": 100,  # Overlap between chunks for context\n        \"batch_size\": 5  # Process 5 chunks at once\n    }\n)\n\nawait enhance_article(article, llm_config)\n</code></pre>"},{"location":"advanced/performance/#parallel-processing","title":"Parallel Processing","text":"<p>For multiple articles, use parallel processing:</p> <pre><code>from medium_converter import batch_convert\n\nawait batch_convert(\n    urls=[\"url1\", \"url2\", \"url3\"],\n    output_format=\"markdown\",\n    output_dir=\"./articles\",\n    max_concurrent=3,  # Process 3 articles at once\n    enhance=True,\n    enhancement_options={\n        \"parallel_blocks\": True  # Process multiple content blocks in parallel\n    }\n)\n</code></pre>"},{"location":"advanced/performance/#memory-management","title":"Memory Management","text":""},{"location":"advanced/performance/#reducing-memory-usage","title":"Reducing Memory Usage","text":"<pre><code># Configure for lower memory usage\nawait convert_article(\n    url=\"https://medium.com/example\",\n    memory_options={\n        \"low_memory\": True,  # Use more disk, less RAM\n        \"cleanup_temporary\": True,  # Aggressively clean temp files\n        \"stream_output\": True  # Stream output rather than building in memory\n    }\n)\n</code></pre>"},{"location":"advanced/performance/#handling-large-articles","title":"Handling Large Articles","text":"<p>For very large articles, use streaming mode:</p> <pre><code>from medium_converter import convert_article_stream\n\nasync for chunk in convert_article_stream(\n    url=\"https://medium.com/example-large-article\",\n    output_format=\"markdown\",\n    chunk_size=1000  # Process 1000 lines at a time\n):\n    # Process each chunk as it becomes available\n    with open(\"large_article.md\", \"a\") as f:\n        f.write(chunk)\n</code></pre>"},{"location":"advanced/performance/#profiling-and-benchmarking","title":"Profiling and Benchmarking","text":""},{"location":"advanced/performance/#performance-logging","title":"Performance Logging","text":"<p>Enable performance logging to identify bottlenecks:</p> <pre><code>import logging\nfrom medium_converter import convert_article\n\n# Set up logging\nlogging.basicConfig(level=logging.INFO)\nperformance_logger = logging.getLogger(\"medium_converter.performance\")\nperformance_logger.setLevel(logging.DEBUG)\n\n# Add a handler to log to file\nfh = logging.FileHandler(\"performance.log\")\nfh.setLevel(logging.DEBUG)\nperformance_logger.addHandler(fh)\n\n# Now perform conversion with performance logging\nawait convert_article(\n    url=\"https://medium.com/example\",\n    output_format=\"markdown\",\n    debug_options={\n        \"profile\": True,  # Enable profiling\n        \"measure_time\": True,  # Measure execution time of each step\n        \"log_memory\": True,  # Log memory usage\n    }\n)\n</code></pre>"},{"location":"advanced/performance/#comparing-configurations","title":"Comparing Configurations","text":"<pre><code>import time\nimport asyncio\nfrom medium_converter import convert_article\n\nasync def benchmark():\n    url = \"https://medium.com/example\"\n    configs = [\n        {\"name\": \"Default\", \"options\": {}},\n        {\"name\": \"Optimized I/O\", \"options\": {\"http2\": True, \"cache\": True}},\n        {\"name\": \"Low Memory\", \"options\": {\"low_memory\": True}},\n        {\"name\": \"High Performance\", \"options\": {\n            \"http2\": True, \n            \"cache\": True,\n            \"parallel_blocks\": True,\n            \"optimize_for\": \"speed\"\n        }}\n    ]\n\n    results = []\n    for config in configs:\n        start_time = time.time()\n\n        await convert_article(\n            url=url,\n            output_format=\"markdown\",\n            **config[\"options\"]\n        )\n\n        end_time = time.time()\n        results.append({\n            \"name\": config[\"name\"],\n            \"time\": end_time - start_time\n        })\n\n    # Print results\n    for result in results:\n        print(f\"{result['name']}: {result['time']:.2f} seconds\")\n\nasyncio.run(benchmark())\n</code></pre>"},{"location":"advanced/performance/#advanced-configurations","title":"Advanced Configurations","text":""},{"location":"advanced/performance/#configuration-for-high-performance-servers","title":"Configuration for High-Performance Servers","text":"<pre><code>from medium_converter import convert_article\n\n# Configuration for high-performance servers\nawait convert_article(\n    url=\"https://medium.com/example\",\n    server_options={\n        \"workers\": 8,  # Number of worker processes\n        \"thread_pool_size\": 20,  # Size of thread pool\n        \"use_uvloop\": True,  # Use uvloop for better asyncio performance\n        \"use_process_pool\": True  # Use process pool for CPU-bound tasks\n    }\n)\n</code></pre>"},{"location":"advanced/performance/#distributed-processing","title":"Distributed Processing","text":"<p>For very large batch operations, you can distribute work:</p> <pre><code>import asyncio\nfrom medium_converter import batch_convert\nfrom concurrent.futures import ProcessPoolExecutor\n\nasync def process_batch(batch_urls):\n    return await batch_convert(\n        urls=batch_urls,\n        output_format=\"markdown\",\n        output_dir=\"./articles\"\n    )\n\nasync def distributed_processing(all_urls, num_processes=4):\n    # Split URLs into batches\n    batch_size = len(all_urls) // num_processes\n    batches = [all_urls[i:i+batch_size] for i in range(0, len(all_urls), batch_size)]\n\n    # Process each batch in a separate process\n    with ProcessPoolExecutor(max_workers=num_processes) as executor:\n        loop = asyncio.get_event_loop()\n        tasks = [\n            loop.run_in_executor(executor, asyncio.run, process_batch(batch))\n            for batch in batches\n        ]\n\n        results = await asyncio.gather(*tasks)\n        return [item for sublist in results for item in sublist]  # Flatten results\n\n# Usage\nall_urls = [f\"https://medium.com/article{i}\" for i in range(1, 101)]\nasyncio.run(distributed_processing(all_urls, num_processes=4))\n</code></pre>"},{"location":"advanced/performance/#final-performance-checklist","title":"Final Performance Checklist","text":"<ul> <li>\u2705 Choose the right output format for your needs</li> <li>\u2705 Configure HTTP client appropriately</li> <li>\u2705 Enable caching for repeated access</li> <li>\u2705 Select appropriate LLM model for your quality/speed requirements</li> <li>\u2705 Use batching and parallel processing when appropriate</li> <li>\u2705 Monitor memory usage for large articles</li> <li>\u2705 Keep dependencies updated</li> <li>\u2705 Use Python 3.11+ for best performance</li> </ul>"},{"location":"advanced/troubleshooting/","title":"Troubleshooting","text":"<p>This guide helps you diagnose and fix common issues with Medium Converter.</p>"},{"location":"advanced/troubleshooting/#common-issues","title":"Common Issues","text":""},{"location":"advanced/troubleshooting/#installation-problems","title":"Installation Problems","text":""},{"location":"advanced/troubleshooting/#missing-dependencies","title":"Missing Dependencies","text":"<p>Symptoms: - <code>ImportError</code> or <code>ModuleNotFoundError</code> when running Medium Converter - Error messages about missing packages</p> <p>Solutions:</p> <pre><code># Reinstall with all dependencies\npip install medium-converter[all]\n\n# Or install specific extras\npip install medium-converter[pdf,llm]\n\n# Check installed dependencies\npip list | grep medium-converter\n</code></pre>"},{"location":"advanced/troubleshooting/#compatibility-issues","title":"Compatibility Issues","text":"<p>Symptoms: - Errors mentioning Python version compatibility - Package conflicts</p> <p>Solutions:</p> <pre><code># Check your Python version\npython --version\n\n# Ensure you're using Python 3.11 or higher\n# Create a fresh virtual environment\npython -m venv venv\nsource venv/bin/activate  # On Windows: venv\\Scripts\\activate\n\n# Install with isolation to avoid dependency conflicts\npip install --isolated medium-converter\n</code></pre>"},{"location":"advanced/troubleshooting/#connection-issues","title":"Connection Issues","text":""},{"location":"advanced/troubleshooting/#failed-to-fetch-article","title":"Failed to Fetch Article","text":"<p>Symptoms: - <code>ConnectionError</code> or <code>HTTPError</code> - Timeout errors - \"Failed to fetch article\" message</p> <p>Solutions:</p> <pre><code># Increase timeout and retry attempts\nfrom medium_converter import convert_article\n\nawait convert_article(\n    url=\"https://medium.com/example\",\n    http_options={\n        \"timeout\": 60,  # Seconds\n        \"retries\": 3,\n        \"backoff_factor\": 2  # Exponential backoff\n    }\n)\n</code></pre> <p>Also check: - Your internet connection - If the Medium article URL is valid - If Medium's servers are experiencing issues</p>"},{"location":"advanced/troubleshooting/#proxy-configuration","title":"Proxy Configuration","text":"<p>Symptoms: - Connection errors in environments with proxies</p> <p>Solutions:</p> <pre><code># Configure proxy settings\nfrom medium_converter import convert_article\n\nawait convert_article(\n    url=\"https://medium.com/example\",\n    http_options={\n        \"proxies\": {\n            \"http\": \"http://proxy.example.com:8080\",\n            \"https\": \"http://proxy.example.com:8080\"\n        }\n    }\n)\n</code></pre> <p>Or set environment variables:</p> <pre><code>export HTTP_PROXY=\"http://proxy.example.com:8080\"\nexport HTTPS_PROXY=\"http://proxy.example.com:8080\"\n</code></pre>"},{"location":"advanced/troubleshooting/#paywall-access-issues","title":"Paywall Access Issues","text":""},{"location":"advanced/troubleshooting/#cookie-extraction-failures","title":"Cookie Extraction Failures","text":"<p>Symptoms: - \"Unable to extract cookies from browser\" errors - Paywall content not accessible despite having a Medium membership</p> <p>Solutions:</p> <ol> <li>Manually provide cookies:</li> </ol> <pre><code>from medium_converter import convert_article\n\nawait convert_article(\n    url=\"https://medium.com/example\",\n    cookies={\n        \"sid\": \"your_sid_cookie_value\",\n        \"uid\": \"your_uid_cookie_value\"\n    }\n)\n</code></pre> <ol> <li>Check if your browser stores cookies in an accessible location</li> <li>Ensure you're logged into Medium in your browser</li> <li>Try a different supported browser</li> </ol>"},{"location":"advanced/troubleshooting/#export-format-issues","title":"Export Format Issues","text":""},{"location":"advanced/troubleshooting/#pdf-generation-problems","title":"PDF Generation Problems","text":"<p>Symptoms: - <code>ReportLabError</code> or other PDF-related errors - Missing fonts or corrupted PDF output</p> <p>Solutions:</p> <pre><code># Configure PDF generation options\nfrom medium_converter import convert_article\n\nawait convert_article(\n    url=\"https://medium.com/example\",\n    output_format=\"pdf\",\n    export_options={\n        \"default_font\": \"Helvetica\",  # Use standard font\n        \"embed_fonts\": True,\n        \"fallback_fonts\": [\"Arial\", \"Times New Roman\"],\n        \"handle_errors\": \"strict\"  # Options: \"ignore\", \"warn\", \"strict\"\n    }\n)\n</code></pre>"},{"location":"advanced/troubleshooting/#image-processing-issues","title":"Image Processing Issues","text":"<p>Symptoms: - Missing images in output - Image download errors</p> <p>Solutions:</p> <pre><code># Configure image handling\nfrom medium_converter import convert_article\n\nawait convert_article(\n    url=\"https://medium.com/example\",\n    export_options={\n        \"image_options\": {\n            \"download_timeout\": 30,  # Seconds per image\n            \"max_size\": 10 * 1024 * 1024,  # 10MB max size\n            \"skip_on_error\": True,  # Continue if an image fails\n            \"alternative_cdn\": True  # Try alternative CDNs if primary fails\n        }\n    }\n)\n</code></pre>"},{"location":"advanced/troubleshooting/#llm-enhancement-issues","title":"LLM Enhancement Issues","text":""},{"location":"advanced/troubleshooting/#api-key-problems","title":"API Key Problems","text":"<p>Symptoms: - Authentication errors with LLM providers - \"Invalid API key\" or similar errors</p> <p>Solutions:</p> <ol> <li>Check your API key is valid and has sufficient permissions/credits</li> <li>Ensure environment variables are set correctly:</li> </ol> <pre><code># For OpenAI\nexport OPENAI_API_KEY=\"your_key_here\"\n\n# For Anthropic\nexport ANTHROPIC_API_KEY=\"your_key_here\"\n\n# For other providers\nexport GOOGLE_API_KEY=\"your_key_here\"\nexport MISTRAL_API_KEY=\"your_key_here\"\n</code></pre> <ol> <li>Provide the API key directly:</li> </ol> <pre><code>from medium_converter import convert_article\nfrom medium_converter.llm.config import LLMConfig, LLMProvider\n\nllm_config = LLMConfig(\n    provider=LLMProvider.OPENAI,\n    api_key=\"your_actual_api_key_here\"\n)\n\nawait convert_article(\n    url=\"https://medium.com/example\",\n    enhance=True,\n    llm_config=llm_config\n)\n</code></pre>"},{"location":"advanced/troubleshooting/#token-limit-exceeded","title":"Token Limit Exceeded","text":"<p>Symptoms: - Context length or token limit errors from LLM providers</p> <p>Solutions:</p> <pre><code># Enable chunking to handle large articles\nfrom medium_converter import convert_article\nfrom medium_converter.llm.config import LLMConfig\n\nllm_config = LLMConfig(\n    chunking={\n        \"enable\": True,\n        \"max_chunk_size\": 1000,\n        \"overlap\": 50\n    }\n)\n\nawait convert_article(\n    url=\"https://medium.com/example\",\n    enhance=True,\n    llm_config=llm_config\n)\n</code></pre>"},{"location":"advanced/troubleshooting/#memory-and-performance-issues","title":"Memory and Performance Issues","text":""},{"location":"advanced/troubleshooting/#out-of-memory-errors","title":"Out of Memory Errors","text":"<p>Symptoms: - <code>MemoryError</code> or process killed - System becomes unresponsive</p> <p>Solutions:</p> <pre><code># Configure for low memory usage\nfrom medium_converter import convert_article\n\nawait convert_article(\n    url=\"https://medium.com/example\",\n    memory_options={\n        \"low_memory\": True,\n        \"max_image_size\": 1024 * 1024,  # 1MB max per image\n        \"stream_processing\": True,\n        \"cleanup_interval\": 10  # Seconds between memory cleanup\n    }\n)\n</code></pre>"},{"location":"advanced/troubleshooting/#slow-processing","title":"Slow Processing","text":"<p>Symptoms: - Conversion takes a very long time</p> <p>Solutions:</p> <p>See the Performance Optimization guide for detailed strategies.</p> <pre><code># Basic performance optimization\nfrom medium_converter import convert_article\n\nawait convert_article(\n    url=\"https://medium.com/example\",\n    performance_options={\n        \"optimize_for\": \"speed\",  # Options: \"quality\", \"balance\", \"speed\"\n        \"parallel_processing\": True,\n        \"skip_unnecessary_steps\": True\n    }\n)\n</code></pre>"},{"location":"advanced/troubleshooting/#debugging-techniques","title":"Debugging Techniques","text":""},{"location":"advanced/troubleshooting/#enabling-debug-logging","title":"Enabling Debug Logging","text":"<pre><code>import logging\nfrom medium_converter import convert_article\n\n# Configure logging\nlogging.basicConfig(\n    level=logging.DEBUG,\n    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n    handlers=[\n        logging.FileHandler(\"medium_converter_debug.log\"),\n        logging.StreamHandler()\n    ]\n)\n\n# Specific module logging\nlogging.getLogger(\"medium_converter.core.fetcher\").setLevel(logging.DEBUG)\nlogging.getLogger(\"medium_converter.llm\").setLevel(logging.DEBUG)\n\n# Now run your conversion\nawait convert_article(\n    url=\"https://medium.com/example\",\n    debug=True  # Enable all debug features\n)\n</code></pre>"},{"location":"advanced/troubleshooting/#command-line-debugging","title":"Command Line Debugging","text":"<pre><code># Enable verbose output\nmedium convert https://medium.com/example -v\n\n# Maximum verbosity\nmedium convert https://medium.com/example -vvv\n\n# Debug mode with full stack traces\nmedium convert https://medium.com/example --debug\n\n# Export debug information to file\nmedium convert https://medium.com/example --debug --log-file debug.log\n</code></pre>"},{"location":"advanced/troubleshooting/#capturing-data-for-bug-reports","title":"Capturing Data for Bug Reports","text":"<pre><code>from medium_converter import convert_article\n\nawait convert_article(\n    url=\"https://medium.com/example\",\n    debug_options={\n        \"capture_inputs\": True,  # Store input data\n        \"capture_outputs\": True,  # Store output data\n        \"capture_http\": True,  # Store HTTP requests/responses\n        \"debug_dir\": \"./debug_output\"  # Where to store debug information\n    }\n)\n</code></pre>"},{"location":"advanced/troubleshooting/#contacting-support","title":"Contacting Support","text":"<p>If you encounter an issue that you can't resolve, please create a GitHub issue with the following information:</p> <ol> <li>Medium Converter version: <code>pip show medium-converter</code></li> <li>Python version: <code>python --version</code></li> <li>Operating system and version</li> <li>Full error message and stack trace</li> <li>Steps to reproduce the issue</li> <li>Any debugging logs you've collected</li> </ol> <p>Create issues at: https://github.com/MarcusElwin/medium-converter/issues</p>"},{"location":"advanced/troubleshooting/#common-error-reference","title":"Common Error Reference","text":"Error Code Description Typical Solution <code>MC-E001</code> Connection error Check internet connection, URL validity <code>MC-E002</code> Authentication error Verify API keys or cookies <code>MC-E003</code> Parser error Article might have unusual formatting <code>MC-E004</code> Export format error Install required dependencies <code>MC-E005</code> LLM provider error Check API key and provider status <code>MC-E006</code> Memory error Use low memory options <code>MC-E007</code> File system error Check permissions and disk space <code>MC-E008</code> Configuration error Verify configuration values <p>For a complete error reference, see the API documentation.</p>"},{"location":"api-reference/core/","title":"Core API Reference","text":"<p>This page documents the core modules of Medium Converter.</p>"},{"location":"api-reference/core/#article-model","title":"Article Model","text":""},{"location":"api-reference/core/#medium_converter.core.models.Article","title":"<code>medium_converter.core.models.Article</code>","text":"<p>A Medium article.</p>"},{"location":"api-reference/core/#fetcher","title":"Fetcher","text":""},{"location":"api-reference/core/#medium_converter.core.fetcher.fetch_article","title":"<code>medium_converter.core.fetcher.fetch_article(url, cookies=None)</code>  <code>async</code>","text":"<p>Fetch a Medium article's HTML content.</p> PARAMETER DESCRIPTION <code>url</code> <p>The URL of the Medium article</p> <p> TYPE: <code>str</code> </p> <code>cookies</code> <p>Optional cookies for authentication</p> <p> TYPE: <code>dict[str, str] | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>str</code> <p>HTML content of the article</p> Source code in <code>medium_converter/core/fetcher.py</code> <pre><code>async def fetch_article(url: str, cookies: dict[str, str] | None = None) -&gt; str:\n    \"\"\"Fetch a Medium article's HTML content.\n\n    Args:\n        url: The URL of the Medium article\n        cookies: Optional cookies for authentication\n\n    Returns:\n        HTML content of the article\n    \"\"\"\n    async with httpx.AsyncClient(follow_redirects=True, cookies=cookies) as client:\n        response = await client.get(url)\n        response.raise_for_status()\n        return response.text\n</code></pre>"},{"location":"api-reference/core/#parser","title":"Parser","text":""},{"location":"api-reference/core/#medium_converter.core.parser.parse_article","title":"<code>medium_converter.core.parser.parse_article(html)</code>","text":"<p>Parse a Medium article's HTML content.</p> PARAMETER DESCRIPTION <code>html</code> <p>The HTML content of the Medium article</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Article</code> <p>Structured Article object</p> Source code in <code>medium_converter/core/parser.py</code> <pre><code>def parse_article(html: str) -&gt; Article:\n    \"\"\"Parse a Medium article's HTML content.\n\n    Args:\n        html: The HTML content of the Medium article\n\n    Returns:\n        Structured Article object\n    \"\"\"\n    BeautifulSoup(html, \"lxml\")\n    # Placeholder implementation\n    return Article(\n        title=\"Sample Article Title\",\n        author=\"Sample Author\",\n        date=\"2023-01-01\",\n        content=[],\n        estimated_reading_time=5,\n    )\n</code></pre>"},{"location":"api-reference/core/#authentication","title":"Authentication","text":""},{"location":"api-reference/core/#medium_converter.core.auth.get_medium_cookies","title":"<code>medium_converter.core.auth.get_medium_cookies()</code>","text":"<p>Extract Medium cookies from the user's browser.</p> RETURNS DESCRIPTION <code>dict[str, str]</code> <p>Dict of cookies for Medium domain</p> Source code in <code>medium_converter/core/auth.py</code> <pre><code>def get_medium_cookies() -&gt; dict[str, str]:\n    \"\"\"Extract Medium cookies from the user's browser.\n\n    Returns:\n        Dict of cookies for Medium domain\n    \"\"\"\n    try:\n        cookies = browser_cookie3.chrome(domain_name=\"medium.com\")\n        return {cookie.name: cookie.value for cookie in cookies}\n    except Exception:\n        # Fallback to Firefox\n        try:\n            cookies = browser_cookie3.firefox(domain_name=\"medium.com\")\n            return {cookie.name: cookie.value for cookie in cookies}\n        except Exception:\n            return {}\n</code></pre>"},{"location":"api-reference/exporters/","title":"Exporters API Reference","text":"<p>This page documents the exporter modules of Medium Converter.</p>"},{"location":"api-reference/exporters/#base-exporter","title":"Base Exporter","text":""},{"location":"api-reference/exporters/#medium_converter.exporters.base.BaseExporter","title":"<code>medium_converter.exporters.base.BaseExporter</code>","text":"<p>Base class for all exporters.</p>"},{"location":"api-reference/exporters/#medium_converter.exporters.base.BaseExporter.export","title":"<code>export(article, output=None)</code>  <code>abstractmethod</code>","text":"<p>Export an article to the target format.</p> PARAMETER DESCRIPTION <code>article</code> <p>The article to export</p> <p> TYPE: <code>Article</code> </p> <code>output</code> <p>Optional output file path or file-like object</p> <p> TYPE: <code>str | TextIO | BinaryIO | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>str | bytes</code> <p>The exported content as string or bytes</p> Source code in <code>medium_converter/exporters/base.py</code> <pre><code>@abstractmethod\ndef export(\n    self, article: Article, output: str | TextIO | BinaryIO | None = None\n) -&gt; str | bytes:\n    \"\"\"Export an article to the target format.\n\n    Args:\n        article: The article to export\n        output: Optional output file path or file-like object\n\n    Returns:\n        The exported content as string or bytes\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api-reference/exporters/#markdown-exporter","title":"Markdown Exporter","text":""},{"location":"api-reference/exporters/#medium_converter.exporters.markdown.MarkdownExporter","title":"<code>medium_converter.exporters.markdown.MarkdownExporter</code>","text":"<p>Export Medium articles to Markdown format.</p>"},{"location":"api-reference/exporters/#medium_converter.exporters.markdown.MarkdownExporter.export","title":"<code>export(article, output=None)</code>","text":"<p>Export an article to Markdown.</p> PARAMETER DESCRIPTION <code>article</code> <p>The article to export</p> <p> TYPE: <code>Article</code> </p> <code>output</code> <p>Optional output file path or file-like object</p> <p> TYPE: <code>str | TextIO | BinaryIO | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>str</code> <p>The exported content as string</p> Source code in <code>medium_converter/exporters/markdown.py</code> <pre><code>def export(\n    self, article: Article, output: str | TextIO | BinaryIO | None = None\n) -&gt; str:\n    \"\"\"Export an article to Markdown.\n\n    Args:\n        article: The article to export\n        output: Optional output file path or file-like object\n\n    Returns:\n        The exported content as string\n    \"\"\"\n    md_content = f\"# {article.title}\\n\\n\"\n    md_content += f\"By {article.author} | {article.date}\\n\\n\"\n\n    if article.tags:\n        tags = \", \".join([f\"#{tag.replace(' ', '')}\" for tag in article.tags])\n        md_content += f\"{tags}\\n\\n\"\n\n    if article.estimated_reading_time:\n        md_content += f\"*{article.estimated_reading_time} min read*\\n\\n\"\n\n    # Process content\n    for item in article.content:\n        if isinstance(item, Section):\n            if item.title:\n                md_content += f\"## {item.title}\\n\\n\"\n\n            for block in item.blocks:\n                md_content += self._format_block(block)\n        elif isinstance(item, ContentBlock):\n            md_content += self._format_block(item)\n\n    # Write to file if specified\n    if output:\n        if isinstance(output, str):\n            with open(output, \"w\", encoding=\"utf-8\") as f:\n                f.write(md_content)\n        else:\n            # We need to check the type to avoid mypy errors\n            if hasattr(output, \"write\") and callable(output.write):\n                if isinstance(output, BinaryIO):\n                    output.write(md_content.encode(\"utf-8\"))\n                else:\n                    # Assume TextIO\n                    output.write(md_content)\n\n    return md_content\n</code></pre>"},{"location":"api-reference/exporters/#pdf-exporter","title":"PDF Exporter","text":""},{"location":"api-reference/exporters/#medium_converter.exporters.pdf.PDFExporter","title":"<code>medium_converter.exporters.pdf.PDFExporter</code>","text":"<p>Export Medium articles to PDF format.</p>"},{"location":"api-reference/exporters/#medium_converter.exporters.pdf.PDFExporter.export","title":"<code>export(article, output=None)</code>","text":"<p>Export an article to PDF.</p> PARAMETER DESCRIPTION <code>article</code> <p>The article to export</p> <p> TYPE: <code>Article</code> </p> <code>output</code> <p>Optional output file path or file-like object</p> <p> TYPE: <code>str | TextIO | BinaryIO | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>bytes</code> <p>The exported content as bytes</p> Source code in <code>medium_converter/exporters/pdf.py</code> <pre><code>def export(\n    self, article: Article, output: str | TextIO | BinaryIO | None = None\n) -&gt; bytes:\n    \"\"\"Export an article to PDF.\n\n    Args:\n        article: The article to export\n        output: Optional output file path or file-like object\n\n    Returns:\n        The exported content as bytes\n    \"\"\"\n    try:\n        from io import BytesIO\n\n        # reportlab imports\n        from reportlab.lib import colors\n        from reportlab.lib.pagesizes import A4\n        from reportlab.lib.styles import ParagraphStyle, getSampleStyleSheet\n        from reportlab.lib.units import inch\n        from reportlab.platypus import (\n            Paragraph,\n            SimpleDocTemplate,\n            Spacer,\n        )\n    except ImportError as err:\n        raise ImportError(\n            \"PDF export requires reportlab.\"\n            \"Install with 'pip install medium-converter[pdf]'\"\n        ) from err\n\n    # Create a buffer for the PDF\n    buffer = BytesIO()\n\n    # Create the PDF document\n    doc = SimpleDocTemplate(\n        buffer if output is None else output if isinstance(output, str) else buffer,\n        pagesize=A4,\n        title=article.title,\n        author=article.author,\n    )\n\n    # Get styles\n    styles = getSampleStyleSheet()\n    title_style = styles[\"Title\"]\n    styles[\"Heading1\"]\n    styles[\"Heading2\"]\n    normal_style = styles[\"Normal\"]\n\n    # Create PDF elements\n    elements = []\n\n    # Add title\n    elements.append(Paragraph(article.title, title_style))\n    elements.append(Spacer(1, 0.2 * inch))\n\n    # Add author and date\n    elements.append(\n        Paragraph(f\"By {article.author} | {article.date}\", normal_style)\n    )\n    elements.append(Spacer(1, 0.2 * inch))\n\n    # Add reading time if available\n    if article.estimated_reading_time:\n        elements.append(\n            Paragraph(\n                f\"{article.estimated_reading_time} min read\",\n                ParagraphStyle(\n                    \"Italic\", parent=normal_style, textColor=colors.gray\n                ),\n            )\n        )\n        elements.append(Spacer(1, 0.2 * inch))\n\n    # Example code to process content (placeholder)\n    elements.append(\n        Paragraph(\n            \"Content will be rendered here in the actual implementation\",\n            normal_style,\n        )\n    )\n\n    # Build the PDF\n    doc.build(elements)\n\n    # Get the PDF content\n    pdf_content = buffer.getvalue()\n    buffer.close()\n\n    # Write to file if specified and not already written\n    if output and isinstance(output, str):\n        with open(output, \"wb\") as f:\n            f.write(pdf_content)\n\n    return pdf_content\n</code></pre>"},{"location":"api-reference/llm/","title":"LLM API Reference","text":"<p>This page documents the LLM enhancement modules of Medium Converter.</p>"},{"location":"api-reference/llm/#configuration","title":"Configuration","text":""},{"location":"api-reference/llm/#medium_converter.llm.config.LLMConfig","title":"<code>medium_converter.llm.config.LLMConfig</code>","text":"<p>Configuration for LLM integration.</p>"},{"location":"api-reference/llm/#medium_converter.llm.config.LLMConfig.from_env","title":"<code>from_env()</code>  <code>classmethod</code>","text":"<p>Create LLM config from environment variables.</p> RETURNS DESCRIPTION <code>LLMConfig</code> <p>LLMConfig instance with values from environment</p> Source code in <code>medium_converter/llm/config.py</code> <pre><code>@classmethod\ndef from_env(cls) -&gt; \"LLMConfig\":\n    \"\"\"Create LLM config from environment variables.\n\n    Returns:\n        LLMConfig instance with values from environment\n    \"\"\"\n    import os\n\n    # Default to OpenAI if OPENAI_API_KEY is set\n    if os.environ.get(\"OPENAI_API_KEY\"):\n        return cls(\n            provider=LLMProvider.OPENAI,\n            api_key=os.environ.get(\"OPENAI_API_KEY\"),\n            model=os.environ.get(\"OPENAI_MODEL\", \"gpt-3.5-turbo\"),\n        )\n\n    # Check for Anthropic\n    if os.environ.get(\"ANTHROPIC_API_KEY\"):\n        return cls(\n            provider=LLMProvider.ANTHROPIC,\n            api_key=os.environ.get(\"ANTHROPIC_API_KEY\"),\n            model=os.environ.get(\"ANTHROPIC_MODEL\", \"claude-3-sonnet-20240229\"),\n        )\n\n    # Check for Google\n    if os.environ.get(\"GOOGLE_API_KEY\"):\n        return cls(\n            provider=LLMProvider.GOOGLE,\n            api_key=os.environ.get(\"GOOGLE_API_KEY\"),\n            model=os.environ.get(\"GOOGLE_MODEL\", \"gemini-pro\"),\n        )\n\n    # Check for Mistral\n    if os.environ.get(\"MISTRAL_API_KEY\"):\n        return cls(\n            provider=LLMProvider.MISTRAL,\n            api_key=os.environ.get(\"MISTRAL_API_KEY\"),\n            model=os.environ.get(\"MISTRAL_MODEL\", \"mistral-medium\"),\n        )\n\n    # Fallback to default\n    return cls()\n</code></pre>"},{"location":"api-reference/llm/#llm-provider","title":"LLM Provider","text":""},{"location":"api-reference/llm/#medium_converter.llm.config.LLMProvider","title":"<code>medium_converter.llm.config.LLMProvider</code>","text":"<p>Supported LLM providers.</p>"},{"location":"api-reference/llm/#enhancer","title":"Enhancer","text":""},{"location":"api-reference/llm/#medium_converter.llm.enhancer.enhance_article","title":"<code>medium_converter.llm.enhancer.enhance_article(article, config=None)</code>  <code>async</code>","text":"<p>Enhance an article using LLM.</p> PARAMETER DESCRIPTION <code>article</code> <p>The article to enhance</p> <p> TYPE: <code>Article</code> </p> <code>config</code> <p>Optional LLM configuration</p> <p> TYPE: <code>LLMConfig | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Article</code> <p>Enhanced article</p> Source code in <code>medium_converter/llm/enhancer.py</code> <pre><code>async def enhance_article(article: Article, config: LLMConfig | None = None) -&gt; Article:\n    \"\"\"Enhance an article using LLM.\n\n    Args:\n        article: The article to enhance\n        config: Optional LLM configuration\n\n    Returns:\n        Enhanced article\n    \"\"\"\n    if config is None:\n        config = LLMConfig.from_env()\n\n    llm = get_llm_client(config)\n\n    # Create a copy of the article to avoid modifying the original\n    enhanced_article = article.model_copy(deep=True)\n\n    # Process each content block through the LLM\n    for item_index, item in enumerate(enhanced_article.content):\n        if isinstance(item, Section):\n            for block_index, block in enumerate(item.blocks):\n                if block.type.value == \"text\":\n                    # Enhance text blocks only\n                    prompt = get_enhancement_prompt(\n                        text=block.content,\n                        article_title=article.title,\n                        context=\"section text\",\n                    )\n\n                    try:\n                        enhanced_text = await llm.generate(prompt)\n                        # Use a type check to satisfy mypy\n                        content_item = enhanced_article.content[item_index]\n                        if isinstance(content_item, Section):\n                            content_item.blocks[block_index].content = enhanced_text\n                    except Exception as e:\n                        # Log error but continue with original content\n                        print(f\"Error enhancing content: {e}\")\n\n        elif isinstance(item, ContentBlock) and item.type.value == \"text\":\n            prompt = get_enhancement_prompt(\n                text=item.content, article_title=article.title, context=\"article text\"\n            )\n\n            try:\n                enhanced_text = await llm.generate(prompt)\n                # Use a type check to satisfy mypy\n                content_item = enhanced_article.content[item_index]\n                if isinstance(content_item, ContentBlock):\n                    content_item.content = enhanced_text\n            except Exception as e:\n                # Log error but continue with original content\n                print(f\"Error enhancing content: {e}\")\n\n    return enhanced_article\n</code></pre>"},{"location":"api-reference/llm/#providers","title":"Providers","text":""},{"location":"api-reference/llm/#medium_converter.llm.providers.LLMClient","title":"<code>medium_converter.llm.providers.LLMClient(config)</code>","text":"<p>Base class for LLM clients.</p> <p>Initialize the LLM client.</p> PARAMETER DESCRIPTION <code>config</code> <p>LLM configuration</p> <p> TYPE: <code>LLMConfig</code> </p> Source code in <code>medium_converter/llm/providers.py</code> <pre><code>def __init__(self, config: LLMConfig):\n    \"\"\"Initialize the LLM client.\n\n    Args:\n        config: LLM configuration\n    \"\"\"\n    self.config = config\n</code></pre>"},{"location":"api-reference/llm/#medium_converter.llm.providers.LLMClient.generate","title":"<code>generate(prompt)</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Generate text from a prompt.</p> PARAMETER DESCRIPTION <code>prompt</code> <p>The prompt to generate from</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>str</code> <p>Generated text</p> Source code in <code>medium_converter/llm/providers.py</code> <pre><code>@abstractmethod\nasync def generate(self, prompt: str) -&gt; str:\n    \"\"\"Generate text from a prompt.\n\n    Args:\n        prompt: The prompt to generate from\n\n    Returns:\n        Generated text\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api-reference/llm/#medium_converter.llm.providers.get_llm_client","title":"<code>medium_converter.llm.providers.get_llm_client(config)</code>","text":"<p>Get an LLM client based on the provider.</p> PARAMETER DESCRIPTION <code>config</code> <p>LLM configuration</p> <p> TYPE: <code>LLMConfig</code> </p> RETURNS DESCRIPTION <code>LLMClient</code> <p>LLM client</p> Source code in <code>medium_converter/llm/providers.py</code> <pre><code>def get_llm_client(config: LLMConfig) -&gt; LLMClient:\n    \"\"\"Get an LLM client based on the provider.\n\n    Args:\n        config: LLM configuration\n\n    Returns:\n        LLM client\n    \"\"\"\n    # Always use LiteLLM if available\n    try:\n        # We only need to check if litellm is importable\n        __import__(\"litellm\")\n        return LiteLLMClient(config)\n    except ImportError:\n        pass\n\n    # Fallback to specific providers\n    if config.provider == LLMProvider.OPENAI:\n        return OpenAIClient(config)\n    elif config.provider == LLMProvider.ANTHROPIC:\n        return AnthropicClient(config)\n    elif config.provider == LLMProvider.GOOGLE:\n        return GoogleClient(config)\n    elif config.provider == LLMProvider.MISTRAL:\n        # Placeholder for Mistral client\n        return OpenAIClient(config)  # Temporary use OpenAI client\n    elif config.provider == LLMProvider.LOCAL:\n        # Placeholder for local client\n        return OpenAIClient(config)  # Temporary use OpenAI client\n    else:\n        # Fallback to OpenAI\n        return OpenAIClient(config)\n</code></pre>"},{"location":"contributing/development/","title":"Development Guide","text":"<p>This guide will help you set up a development environment for working on Medium Converter.</p>"},{"location":"contributing/development/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.11 or newer</li> <li>Poetry for dependency management</li> <li>Git for version control</li> </ul>"},{"location":"contributing/development/#getting-started","title":"Getting Started","text":""},{"location":"contributing/development/#clone-the-repository","title":"Clone the Repository","text":"<pre><code>git clone https://github.com/MarcusElwin/medium-converter.git\ncd medium-converter\n</code></pre>"},{"location":"contributing/development/#install-dependencies","title":"Install Dependencies","text":"<pre><code># Install all dependencies including development tools\npoetry install --all-extras\n\n# Or without optional dependencies\npoetry install\n</code></pre>"},{"location":"contributing/development/#activate-the-virtual-environment","title":"Activate the Virtual Environment","text":"<pre><code>poetry shell\n</code></pre>"},{"location":"contributing/development/#project-structure","title":"Project Structure","text":"<pre><code>medium-converter/\n\u251c\u2500\u2500 medium_converter/            # Main package\n\u2502   \u251c\u2500\u2500 __init__.py              # Public API &amp; version\n\u2502   \u251c\u2500\u2500 cli.py                   # CLI interface\n\u2502   \u251c\u2500\u2500 core/                    # Core functionality\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u251c\u2500\u2500 fetcher.py           # HTTP client\n\u2502   \u2502   \u251c\u2500\u2500 parser.py            # HTML parsing\n\u2502   \u2502   \u251c\u2500\u2500 auth.py              # Authentication\n\u2502   \u2502   \u2514\u2500\u2500 models.py            # Data models\n\u2502   \u251c\u2500\u2500 exporters/               # Format exporters \n\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u251c\u2500\u2500 base.py              # Base exporter\n\u2502   \u2502   \u251c\u2500\u2500 markdown.py          # Markdown exporter\n\u2502   \u2502   \u2514\u2500\u2500 ...\n\u2502   \u251c\u2500\u2500 llm/                     # LLM integration\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u251c\u2500\u2500 config.py            # Configuration\n\u2502   \u2502   \u251c\u2500\u2500 enhancer.py          # Content enhancement\n\u2502   \u2502   \u2514\u2500\u2500 ...\n\u2502   \u2514\u2500\u2500 utils/                   # Utilities\n\u2502       \u251c\u2500\u2500 __init__.py\n\u2502       \u2514\u2500\u2500 helpers.py           # Helper functions\n\u251c\u2500\u2500 tests/                       # Test suite\n\u2502   \u251c\u2500\u2500 conftest.py              # Test fixtures\n\u2502   \u251c\u2500\u2500 unit/                    # Unit tests\n\u2502   \u2514\u2500\u2500 integration/             # Integration tests\n\u251c\u2500\u2500 docs/                        # Documentation\n\u251c\u2500\u2500 examples/                    # Example scripts\n\u251c\u2500\u2500 pyproject.toml               # Project configuration\n\u2514\u2500\u2500 README.md                    # Project readme\n</code></pre>"},{"location":"contributing/development/#development-workflow","title":"Development Workflow","text":""},{"location":"contributing/development/#running-tests","title":"Running Tests","text":"<pre><code># Run all tests\npytest\n\n# Run with coverage report\npytest --cov=medium_converter\n\n# Run specific test file\npytest tests/unit/test_models.py\n</code></pre>"},{"location":"contributing/development/#code-style-and-linting","title":"Code Style and Linting","text":"<p>The project uses Black, Ruff, and MyPy for code quality:</p> <pre><code># Format code with Black\nblack medium_converter tests\n\n# Run linter\nruff medium_converter tests\n\n# Run type checks\nmypy medium_converter\n</code></pre>"},{"location":"contributing/development/#building-documentation","title":"Building Documentation","text":"<pre><code># Build documentation\nmkdocs build\n\n# Serve documentation locally\nmkdocs serve\n</code></pre>"},{"location":"contributing/development/#adding-features","title":"Adding Features","text":""},{"location":"contributing/development/#adding-a-new-exporter","title":"Adding a New Exporter","text":"<ol> <li>Create a new file in <code>medium_converter/exporters/</code> (e.g., <code>html.py</code>)</li> <li>Implement the exporter class that inherits from <code>BaseExporter</code></li> <li>Implement the required methods (especially <code>export()</code>)</li> <li>Register the format in <code>medium_converter/cli.py</code></li> <li>Add tests in <code>tests/unit/exporters/</code></li> <li>Add documentation in <code>docs/user-guide/formats/</code></li> </ol> <p>Example:</p> <pre><code># medium_converter/exporters/html.py\nfrom typing import Optional, Union, TextIO\nfrom .base import BaseExporter\nfrom ..core.models import Article\n\nclass HTMLExporter(BaseExporter):\n    \"\"\"Export Medium articles to HTML format.\"\"\"\n\n    def export(self, article: Article, output: Optional[Union[str, TextIO]] = None) -&gt; str:\n        \"\"\"Export an article to HTML.\n\n        Args:\n            article: The article to export\n            output: Optional output file path or file-like object\n\n        Returns:\n            The exported content as string\n        \"\"\"\n        # Implementation here\n        html_content = f\"&lt;!DOCTYPE html&gt;\\n&lt;html&gt;\\n&lt;head&gt;\\n&lt;title&gt;{article.title}&lt;/title&gt;\\n&lt;/head&gt;\\n&lt;body&gt;\\n\"\n        # ... more implementation\n\n        # Write to file if specified\n        if output:\n            if isinstance(output, str):\n                with open(output, 'w', encoding='utf-8') as f:\n                    f.write(html_content)\n            else:\n                output.write(html_content)\n\n        return html_content\n</code></pre>"},{"location":"contributing/development/#adding-a-new-llm-provider","title":"Adding a New LLM Provider","text":"<ol> <li>Create or modify the provider implementation in <code>medium_converter/llm/providers.py</code></li> <li>Add the provider to the <code>LLMProvider</code> enum in <code>medium_converter/llm/config.py</code></li> <li>Implement the client class that inherits from <code>LLMClient</code></li> <li>Update the <code>get_llm_client</code> function to include your provider</li> <li>Add relevant tests</li> <li>Add documentation</li> </ol>"},{"location":"contributing/development/#submitting-changes","title":"Submitting Changes","text":"<ol> <li>Create a new branch: <code>git checkout -b feature/your-feature-name</code></li> <li>Make your changes and commit them with descriptive messages</li> <li>Run tests to ensure everything is working</li> <li>Push your branch: <code>git push origin feature/your-feature-name</code></li> <li>Create a pull request on GitHub</li> </ol>"},{"location":"contributing/development/#release-process","title":"Release Process","text":"<ol> <li>Update version in <code>pyproject.toml</code></li> <li>Update changelog with your changes</li> <li>Run the release script: <code>./scripts/publish.sh</code></li> <li>Create a new release on GitHub</li> </ol>"},{"location":"contributing/development/#code-conventions","title":"Code Conventions","text":"<ul> <li>Use Google style docstrings</li> <li>Follow PEP 8 style guidelines</li> <li>Write comprehensive tests for new features</li> <li>Keep functions small and focused</li> <li>Document all public APIs</li> <li>Use type hints for all functions and methods</li> </ul>"},{"location":"contributing/release-process/","title":"Release Process","text":"<p>This document describes the process for releasing new versions of Medium Converter.</p>"},{"location":"contributing/release-process/#version-numbering","title":"Version Numbering","text":"<p>Medium Converter follows Semantic Versioning (SemVer):</p> <ul> <li>MAJOR version for incompatible API changes</li> <li>MINOR version for new functionality in a backward compatible manner</li> <li>PATCH version for backward compatible bug fixes</li> </ul> <p>Example: <code>1.2.3</code> represents major version 1, minor version 2, patch version 3.</p>"},{"location":"contributing/release-process/#release-checklist","title":"Release Checklist","text":""},{"location":"contributing/release-process/#1-pre-release-checks","title":"1. Pre-release Checks","text":"<ul> <li> Ensure all tests pass: <code>pytest</code></li> <li> Run type checking: <code>mypy medium_converter</code></li> <li> Run linting: <code>ruff medium_converter</code></li> <li> Run code formatting: <code>black medium_converter</code></li> <li> Check test coverage: <code>pytest --cov=medium_converter</code></li> <li> Verify documentation is up-to-date: <code>mkdocs build</code></li> <li> Run the package with key features to ensure everything works</li> <li> Prepare changelog entry</li> </ul>"},{"location":"contributing/release-process/#2-update-version-and-changelog","title":"2. Update Version and Changelog","text":"<ol> <li>Update version in <code>pyproject.toml</code>:</li> </ol> <pre><code>[tool.poetry]\nname = \"medium-converter\"\nversion = \"x.y.z\"  # Update this line\n</code></pre> <ol> <li>Create a changelog entry in <code>CHANGELOG.md</code>:</li> </ol> <pre><code>## [x.y.z] - YYYY-MM-DD\n\n### Added\n- New feature 1\n- New feature 2\n\n### Changed\n- Change 1\n- Change 2\n\n### Fixed\n- Bug fix 1\n- Bug fix 2\n\n### Removed\n- Removed feature 1\n</code></pre> <ol> <li>Commit the changes:</li> </ol> <pre><code>git add pyproject.toml CHANGELOG.md\ngit commit -m \"Bump version to x.y.z\"\n</code></pre>"},{"location":"contributing/release-process/#3-create-git-tag","title":"3. Create Git Tag","text":"<p>Create a Git tag for the release:</p> <pre><code>git tag -a vx.y.z -m \"Version x.y.z\"\ngit push origin vx.y.z\n</code></pre>"},{"location":"contributing/release-process/#4-build-the-package","title":"4. Build the Package","text":"<p>Build the package using Poetry:</p> <pre><code># Clean any previous builds\nrm -rf dist/\n\n# Build the package\npoetry build\n</code></pre> <p>This will create both <code>.tar.gz</code> and <code>.whl</code> files in the <code>dist/</code> directory.</p>"},{"location":"contributing/release-process/#5-test-the-built-package","title":"5. Test the Built Package","text":"<p>Test the built package in a clean environment:</p> <pre><code># Create a temporary directory\nmkdir /tmp/medium-converter-test\ncd /tmp/medium-converter-test\n\n# Create a virtual environment\npython -m venv venv\nsource venv/bin/activate  # On Windows: venv\\Scripts\\activate\n\n# Install the built package\npip install /path/to/medium-converter/dist/medium-converter-x.y.z.tar.gz\n\n# Test basic functionality\npython -c \"import medium_converter; print(medium_converter.__version__)\"\n</code></pre>"},{"location":"contributing/release-process/#6-upload-to-pypi","title":"6. Upload to PyPI","text":"<p>Upload the package to PyPI:</p> <pre><code># First to test PyPI (recommended)\npoetry publish -r testpypi\n\n# Then to real PyPI\npoetry publish\n</code></pre> <p>Or use twine directly:</p> <pre><code># First to test PyPI (recommended)\ntwine upload --repository-url https://test.pypi.org/legacy/ dist/*\n\n# Then to real PyPI\ntwine upload dist/*\n</code></pre>"},{"location":"contributing/release-process/#7-create-github-release","title":"7. Create GitHub Release","text":"<ol> <li>Go to the GitHub releases page</li> <li>Click \"Draft a new release\"</li> <li>Choose the tag you created</li> <li>Fill in the release title (usually \"Version x.y.z\")</li> <li>Copy the changelog entry into the description</li> <li>Upload the distribution files</li> <li>Publish the release</li> </ol>"},{"location":"contributing/release-process/#8-update-documentation","title":"8. Update Documentation","text":"<p>Make sure the documentation is updated on Read the Docs:</p> <ol> <li>Log in to Read the Docs</li> <li>Go to the Medium Converter project</li> <li>Trigger a new build for the latest version</li> <li>Make sure the new version is set as the default version</li> </ol>"},{"location":"contributing/release-process/#9-announce-the-release","title":"9. Announce the Release","text":"<p>Announce the new release in appropriate channels:</p> <ul> <li>GitHub Discussions</li> <li>Twitter/X</li> <li>Reddit (r/Python, etc.)</li> <li>Any other relevant community platforms</li> </ul>"},{"location":"contributing/release-process/#post-release","title":"Post-Release","text":"<p>After a successful release:</p> <ol> <li>Bump the version in <code>pyproject.toml</code> to the next development version with <code>.dev0</code> suffix:</li> </ol> <pre><code>[tool.poetry]\nname = \"medium-converter\"\nversion = \"x.y.(z+1).dev0\"  # Next version with dev suffix\n</code></pre> <ol> <li>Commit this change:</li> </ol> <pre><code>git add pyproject.toml\ngit commit -m \"Bump to development version x.y.(z+1).dev0\"\ngit push origin main\n</code></pre>"},{"location":"contributing/release-process/#hotfix-releases","title":"Hotfix Releases","text":"<p>For critical bugs in a released version:</p> <ol> <li>Create a hotfix branch from the release tag:</li> </ol> <pre><code>git checkout -b hotfix/x.y.(z+1) vx.y.z\n</code></pre> <ol> <li>Fix the bug and update version to <code>x.y.(z+1)</code></li> <li>Update the changelog</li> <li>Commit changes and create a pull request</li> <li>After approval, merge the PR</li> <li>Create a new tag and follow the release process above</li> </ol>"},{"location":"contributing/release-process/#major-releases","title":"Major Releases","text":"<p>For major releases (x.0.0), additional steps are recommended:</p> <ol> <li>Create a release candidate first: <code>x.0.0-rc1</code></li> <li>Get feedback from users</li> <li>Fix any issues and create another RC if needed</li> <li>When stable, release the final version</li> </ol>"},{"location":"contributing/release-process/#versioning-in-the-code","title":"Versioning in the Code","text":"<p>The version number should be available in code:</p> <pre><code># medium_converter/__init__.py\n\"\"\"Medium Converter - Convert Medium articles to various formats with LLM enhancement.\"\"\"\n\nimport importlib.metadata\n\ntry:\n    __version__ = importlib.metadata.version(\"medium-converter\")\nexcept importlib.metadata.PackageNotFoundError:\n    __version__ = \"0.1.0\"  # Default during development\n</code></pre>"},{"location":"contributing/release-process/#automating-the-release-process","title":"Automating the Release Process","text":"<p>A release GitHub Action workflow can automate some of these steps. Here's a basic example:</p> <pre><code>name: Release\n\non:\n  workflow_dispatch:\n    inputs:\n      version:\n        description: 'Version number (e.g., 1.2.3)'\n        required: true\n\njobs:\n  release:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n      - name: Set up Python\n        uses: actions/setup-python@v4\n        with:\n          python-version: '3.11'\n\n      - name: Install dependencies\n        run: |\n          python -m pip install --upgrade pip\n          pip install poetry\n\n      - name: Update version\n        run: |\n          poetry version ${{ github.event.inputs.version }}\n\n      - name: Build and publish\n        env:\n          POETRY_PYPI_TOKEN_PYPI: ${{ secrets.PYPI_TOKEN }}\n        run: |\n          poetry build\n          poetry publish\n\n      - name: Create GitHub Release\n        uses: softprops/action-gh-release@v1\n        with:\n          tag_name: v${{ github.event.inputs.version }}\n          name: Version ${{ github.event.inputs.version }}\n          generate_release_notes: true\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n</code></pre>"},{"location":"contributing/testing/","title":"Testing Guide","text":"<p>This document outlines how to test Medium Converter effectively.</p>"},{"location":"contributing/testing/#setting-up-the-test-environment","title":"Setting Up the Test Environment","text":""},{"location":"contributing/testing/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.11 or newer</li> <li>Poetry installed</li> <li>Git</li> </ul>"},{"location":"contributing/testing/#installation","title":"Installation","text":"<pre><code># Clone the repository if you haven't already\ngit clone https://github.com/MarcusElwin/medium-converter.git\ncd medium-converter\n\n# Install dependencies with development extras\npoetry install --with dev\n\n# Activate the virtual environment\npoetry shell\n</code></pre>"},{"location":"contributing/testing/#running-tests","title":"Running Tests","text":""},{"location":"contributing/testing/#running-all-tests","title":"Running All Tests","text":"<pre><code># Run all tests\npytest\n\n# Run with increased verbosity\npytest -v\n\n# Run with coverage report\npytest --cov=medium_converter\n\n# Generate HTML coverage report\npytest --cov=medium_converter --cov-report=html\n</code></pre>"},{"location":"contributing/testing/#running-specific-tests","title":"Running Specific Tests","text":"<pre><code># Run tests in a specific file\npytest tests/unit/test_models.py\n\n# Run a specific test class\npytest tests/unit/test_models.py::TestArticle\n\n# Run a specific test function\npytest tests/unit/test_models.py::TestArticle::test_article_creation\n\n# Run tests matching a pattern\npytest -k \"models or parser\"\n</code></pre>"},{"location":"contributing/testing/#test-structure","title":"Test Structure","text":"<p>The test suite is organized as follows:</p> <pre><code>tests/\n\u251c\u2500\u2500 conftest.py         # Shared fixtures\n\u251c\u2500\u2500 unit/               # Unit tests\n\u2502   \u251c\u2500\u2500 test_models.py  # Tests for data models\n\u2502   \u251c\u2500\u2500 test_parser.py  # Tests for HTML parsing\n\u2502   \u2514\u2500\u2500 ...\n\u2514\u2500\u2500 integration/        # Integration tests\n    \u251c\u2500\u2500 test_fetcher.py # Tests for article fetching\n    \u251c\u2500\u2500 test_exports.py # Tests for export formats\n    \u2514\u2500\u2500 ...\n</code></pre>"},{"location":"contributing/testing/#test-types","title":"Test Types","text":""},{"location":"contributing/testing/#unit-tests","title":"Unit Tests","text":"<p>Unit tests focus on testing individual components in isolation. These tests are fast and should not make external network calls or depend on external services.</p> <pre><code># Example unit test\ndef test_markdown_exporter_formatting(sample_article):\n    exporter = MarkdownExporter()\n    result = exporter.export(sample_article)\n\n    assert sample_article.title in result\n    assert sample_article.author in result\n    assert \"##\" in result  # Should contain headings\n</code></pre>"},{"location":"contributing/testing/#integration-tests","title":"Integration Tests","text":"<p>Integration tests verify that different components work together correctly. These tests may involve file system operations or mocked external services.</p> <pre><code># Example integration test with mocked response\ndef test_article_fetch_and_parse(mock_httpx_client):\n    # Setup mock response\n    mock_html = \"&lt;html&gt;&lt;body&gt;&lt;article&gt;...&lt;/article&gt;&lt;/body&gt;&lt;/html&gt;\"\n    mock_httpx_client.get.return_value.text = mock_html\n\n    # Run the test\n    article = fetch_and_parse(\"https://example.com/article\")\n\n    # Verify results\n    assert article.title is not None\n    assert len(article.content) &gt; 0\n</code></pre>"},{"location":"contributing/testing/#end-to-end-tests","title":"End-to-End Tests","text":"<p>End-to-end tests verify the whole system works together. These are marked with <code>pytest.mark.e2e</code> and are skipped by default unless explicitly enabled.</p> <pre><code>@pytest.mark.e2e\ndef test_full_conversion_process():\n    # This test actually downloads a public Medium article\n    result = convert_article_sync(\n        url=\"https://medium.com/official-public-test-article\",\n        output_format=\"markdown\",\n        output_path=None  # Return as string\n    )\n\n    assert result is not None\n    assert len(result) &gt; 100\n</code></pre>"},{"location":"contributing/testing/#test-fixtures","title":"Test Fixtures","text":"<p>Common test fixtures are defined in <code>conftest.py</code>:</p> <pre><code>@pytest.fixture\ndef sample_article():\n    \"\"\"Create a sample article for testing.\"\"\"\n    return Article(\n        title=\"Sample Article\",\n        author=\"Test Author\",\n        date=\"2023-01-01\",\n        content=[...],\n        # ...\n    )\n\n@pytest.fixture\ndef mock_httpx_client(monkeypatch):\n    \"\"\"Mock the HTTPX client for testing.\"\"\"\n    mock_client = MagicMock()\n    mock_response = MagicMock()\n    mock_client.return_value.__aenter__.return_value = mock_client\n    mock_client.get.return_value = mock_response\n\n    monkeypatch.setattr(\"httpx.AsyncClient\", mock_client)\n    return mock_client\n</code></pre>"},{"location":"contributing/testing/#mocking-external-services","title":"Mocking External Services","text":""},{"location":"contributing/testing/#mocking-http-requests","title":"Mocking HTTP Requests","text":"<p>For tests that would normally make HTTP requests, use the <code>responses</code> package to mock responses:</p> <pre><code>import responses\n\n@responses.activate\ndef test_fetch_article():\n    # Mock the HTTP response\n    responses.add(\n        responses.GET,\n        \"https://medium.com/test-article\",\n        body=\"&lt;html&gt;&lt;body&gt;&lt;article&gt;Test content&lt;/article&gt;&lt;/body&gt;&lt;/html&gt;\",\n        status=200,\n    )\n\n    # Test the function\n    html = fetch_article_sync(\"https://medium.com/test-article\")\n\n    assert \"Test content\" in html\n</code></pre>"},{"location":"contributing/testing/#mocking-llm-providers","title":"Mocking LLM Providers","text":"<p>For testing LLM enhancement without making actual API calls:</p> <pre><code>@pytest.fixture\ndef mock_llm_client(monkeypatch):\n    \"\"\"Mock LLM client for testing.\"\"\"\n    mock_client = MagicMock()\n    mock_client.generate.return_value = \"Enhanced test content\"\n\n    monkeypatch.setattr(\n        \"medium_converter.llm.providers.get_llm_client\",\n        lambda config: mock_client\n    )\n\n    return mock_client\n\n# Then in your test\ndef test_enhance_article(sample_article, mock_llm_client):\n    enhanced = enhance_article_sync(sample_article)\n\n    assert \"Enhanced test content\" in str(enhanced.content)\n    assert mock_llm_client.generate.called\n</code></pre>"},{"location":"contributing/testing/#test-data","title":"Test Data","text":"<p>Sample test data is stored in the <code>tests/data</code> directory:</p> <pre><code>tests/data/\n\u251c\u2500\u2500 html/               # Sample HTML files\n\u2502   \u251c\u2500\u2500 article1.html   # Complete article\n\u2502   \u2514\u2500\u2500 paywall.html    # Article with paywall\n\u251c\u2500\u2500 responses/          # Sample API responses\n\u2514\u2500\u2500 expected/           # Expected output files\n    \u251c\u2500\u2500 markdown/       # Expected Markdown output\n    \u2514\u2500\u2500 pdf/            # Expected PDF output\n</code></pre> <p>Load test data in tests like this:</p> <pre><code>import os\n\ndef test_parse_article_with_real_html():\n    # Load test HTML file\n    html_path = os.path.join(os.path.dirname(__file__), \"../data/html/article1.html\")\n    with open(html_path, \"r\", encoding=\"utf-8\") as f:\n        html = f.read()\n\n    # Test parsing\n    article = parse_article(html)\n    assert article.title == \"Expected Title\"\n</code></pre>"},{"location":"contributing/testing/#writing-new-tests","title":"Writing New Tests","text":""},{"location":"contributing/testing/#test-driven-development","title":"Test-Driven Development","text":"<p>For new features, consider following test-driven development (TDD):</p> <ol> <li>Write a failing test that describes the expected behavior</li> <li>Implement the minimum code to make the test pass</li> <li>Refactor the code while ensuring tests continue to pass</li> </ol>"},{"location":"contributing/testing/#test-naming-convention","title":"Test Naming Convention","text":"<p>Tests should follow this naming convention:</p> <ul> <li><code>test_[function_name]_[scenario]_[expected_result]</code></li> </ul> <p>Examples: - <code>test_parse_article_with_paywall_returns_partial_content</code> - <code>test_markdown_exporter_with_images_includes_image_links</code></p>"},{"location":"contributing/testing/#testing-complex-async-code","title":"Testing Complex Async Code","text":"<p>Use <code>pytest-asyncio</code> for testing asynchronous code:</p> <pre><code>import pytest\n\n@pytest.mark.asyncio\nasync def test_async_function():\n    result = await async_function()\n    assert result == expected_value\n</code></pre>"},{"location":"contributing/testing/#test-coverage","title":"Test Coverage","text":"<p>Aim for high test coverage, particularly for critical code paths:</p> <pre><code># Generate coverage report\npytest --cov=medium_converter --cov-report=term-missing\n\n# Generate HTML report\npytest --cov=medium_converter --cov-report=html\n</code></pre> <p>The HTML report will be available in the <code>htmlcov</code> directory.</p>"},{"location":"contributing/testing/#continuous-integration","title":"Continuous Integration","text":"<p>Tests are automatically run on GitHub Actions for: - Each pull request - Commits to the main branch</p> <p>The CI pipeline runs: 1. Linting with ruff and black 2. Type checking with mypy 3. Unit tests 4. Integration tests 5. Coverage reporting</p>"},{"location":"contributing/testing/#test-best-practices","title":"Test Best Practices","text":"<ol> <li>Keep tests fast: Slow tests discourage frequent testing</li> <li>One assertion per test: Tests should verify one specific behavior</li> <li>Use descriptive test names: Names should explain the test's purpose</li> <li>Don't test implementation details: Test behavior, not how it's implemented</li> <li>Don't skip tests without a good reason: Skipped tests often indicate problems</li> <li>Run tests often: Catch issues early</li> <li>Avoid test interdependency: Tests should be able to run in any order</li> </ol>"},{"location":"contributing/testing/#troubleshooting-tests","title":"Troubleshooting Tests","text":""},{"location":"contributing/testing/#common-issues","title":"Common Issues","text":"<ol> <li>Flaky tests: If tests sometimes fail, they may have timing issues or external dependencies</li> <li>Slow tests: Look for unnecessary I/O or processing in tests</li> <li>Failing tests: Use <code>pytest -v --tb=native</code> for better error information</li> </ol>"},{"location":"contributing/testing/#debug-options","title":"Debug Options","text":"<pre><code># Show local variables in tracebacks\npytest --showlocals\n\n# Drop into PDB on test failures\npytest --pdb\n\n# Increase verbosity\npytest -vv\n\n# Show slowest tests\npytest --durations=10\n</code></pre>"},{"location":"getting-started/configuration/","title":"Configuration","text":"<p>Medium Converter can be configured in several ways to customize its behavior.</p>"},{"location":"getting-started/configuration/#environment-variables","title":"Environment Variables","text":"<p>Medium Converter looks for the following environment variables:</p>"},{"location":"getting-started/configuration/#authentication","title":"Authentication","text":"<pre><code># Set Medium cookies manually\nMEDIUM_SID=your_sid_cookie\nMEDIUM_UID=your_uid_cookie\n\n# Disable auto-cookie fetching from browser\nMEDIUM_NO_BROWSER_COOKIES=1\n</code></pre>"},{"location":"getting-started/configuration/#llm-configuration","title":"LLM Configuration","text":"<pre><code># OpenAI\nOPENAI_API_KEY=your_openai_api_key\nOPENAI_MODEL=gpt-4  # Defaults to gpt-3.5-turbo\n\n# Anthropic\nANTHROPIC_API_KEY=your_anthropic_api_key\nANTHROPIC_MODEL=claude-3-sonnet-20240229  # Default is claude-3-haiku-20240307\n\n# Google\nGOOGLE_API_KEY=your_google_api_key\nGOOGLE_MODEL=gemini-pro  # Default\n\n# Mistral\nMISTRAL_API_KEY=your_mistral_api_key\nMISTRAL_MODEL=mistral-medium  # Default\n</code></pre>"},{"location":"getting-started/configuration/#export-options","title":"Export Options","text":"<pre><code># Default output directory\nMEDIUM_OUTPUT_DIR=~/Documents/medium-articles\n\n# Default export format\nMEDIUM_DEFAULT_FORMAT=pdf\n</code></pre>"},{"location":"getting-started/configuration/#configuration-file","title":"Configuration File","text":"<p>Medium Converter also looks for a configuration file at <code>~/.medium-converter/config.toml</code>:</p> <pre><code>[general]\ndefault_format = \"markdown\"\noutput_dir = \"~/Documents/medium-articles\"\nuse_browser_cookies = true\n\n[llm]\nprovider = \"openai\"\nmodel = \"gpt-3.5-turbo\"\ntemperature = 0.7\napi_key = \"your_api_key\"  # Better to use environment variable\n\n[export.pdf]\npage_size = \"A4\"\nfont_size = 11\ninclude_images = true\n\n[export.markdown]\nsyntax_highlighting = true\ninclude_frontmatter = true\n</code></pre>"},{"location":"getting-started/configuration/#cli-configuration","title":"CLI Configuration","text":"<p>You can create persistent CLI configuration using the <code>medium config</code> command:</p> <pre><code># Set default export format\nmedium config set default_format pdf\n\n# Set LLM provider\nmedium config set llm.provider openai\n\n# View current configuration\nmedium config show\n\n# Reset to defaults\nmedium config reset\n</code></pre>"},{"location":"getting-started/configuration/#python-api-configuration","title":"Python API Configuration","text":"<p>When using the Python API, you can pass configuration options directly:</p> <pre><code>from medium_converter import convert_article\nfrom medium_converter.llm import LLMConfig, LLMProvider\n\nasync def main():\n    # Configure LLM\n    llm_config = LLMConfig(\n        provider=LLMProvider.ANTHROPIC,\n        model=\"claude-3-sonnet-20240229\",\n        temperature=0.5\n    )\n\n    # Configure export options\n    export_options = {\n        \"include_images\": True,\n        \"syntax_highlighting\": True,\n        \"page_size\": \"A4\",\n        \"font_size\": 11\n    }\n\n    await convert_article(\n        url=\"https://medium.com/example-article\",\n        output_format=\"pdf\",\n        output_path=\"article.pdf\",\n        enhance=True,\n        llm_config=llm_config,\n        export_options=export_options\n    )\n</code></pre>"},{"location":"getting-started/configuration/#configuration-priority","title":"Configuration Priority","text":"<p>Medium Converter configuration is applied in the following order (later items override earlier ones):</p> <ol> <li>Default values</li> <li>Configuration file</li> <li>Environment variables</li> <li>Direct function arguments or CLI options</li> </ol>"},{"location":"getting-started/installation/","title":"Installation","text":"<p>Medium Converter is available on PyPI and can be installed using pip.</p>"},{"location":"getting-started/installation/#basic-installation","title":"Basic Installation","text":"<pre><code>pip install medium-converter\n</code></pre> <p>This installs the core package with basic functionality for fetching and converting Medium articles to Markdown format.</p>"},{"location":"getting-started/installation/#optional-dependencies","title":"Optional Dependencies","text":"<p>Medium Converter uses optional dependencies to keep the base installation light. You can install additional features using \"extras\".</p>"},{"location":"getting-started/installation/#export-formats","title":"Export Formats","text":"<pre><code># For PDF export\npip install medium-converter[pdf]\n\n# For Word DOCX export\npip install medium-converter[word]\n\n# For LaTeX export\npip install medium-converter[latex]\n\n# For EPUB export\npip install medium-converter[epub]\n\n# For HTML export\npip install medium-converter[html]\n\n# For all export formats\npip install medium-converter[all-formats]\n</code></pre>"},{"location":"getting-started/installation/#llm-enhancement","title":"LLM Enhancement","text":"<pre><code># For basic LLM support (required for any LLM provider)\npip install medium-converter[llm]\n\n# For OpenAI (GPT models)\npip install medium-converter[openai]\n\n# For Anthropic (Claude models)\npip install medium-converter[anthropic]\n\n# For Google (Gemini models)\npip install medium-converter[google]\n\n# For Mistral AI\npip install medium-converter[mistral]\n\n# For local models (via llama-cpp-python)\npip install medium-converter[local]\n\n# For all LLM providers\npip install medium-converter[all-llm]\n</code></pre>"},{"location":"getting-started/installation/#development-and-documentation","title":"Development and Documentation","text":"<pre><code># For development dependencies\npip install medium-converter[dev]\n\n# For documentation\npip install medium-converter[docs]\n</code></pre>"},{"location":"getting-started/installation/#all-features","title":"All Features","text":"<pre><code># Install everything\npip install medium-converter[all]\n</code></pre>"},{"location":"getting-started/installation/#installation-from-source","title":"Installation from Source","text":"<p>If you want to install the latest development version or contribute to the project, you can install from source:</p> <pre><code># Clone the repository\ngit clone https://github.com/MarcusElwin/medium-converter.git\ncd medium-converter\n\n# Install with Poetry\npoetry install --all-extras\n\n# Or with pip\npip install -e .\n</code></pre>"},{"location":"getting-started/installation/#system-requirements","title":"System Requirements","text":"<ul> <li>Python 3.11 or higher</li> <li>Windows, macOS, or Linux</li> </ul>"},{"location":"getting-started/quickstart/","title":"Quick Start","text":"<p>This guide will help you get started with Medium Converter quickly.</p>"},{"location":"getting-started/quickstart/#basic-usage","title":"Basic Usage","text":""},{"location":"getting-started/quickstart/#command-line","title":"Command Line","text":"<p>The simplest way to use Medium Converter is through the command line:</p> <pre><code># Convert to Markdown (default)\nmedium convert https://medium.com/example-article\n\n# Convert to PDF\nmedium convert https://medium.com/example-article -f pdf -o article.pdf\n\n# Convert with LLM enhancement\nmedium convert https://medium.com/example-article --enhance\n</code></pre>"},{"location":"getting-started/quickstart/#python-api","title":"Python API","text":"<p>Medium Converter can also be used as a Python library:</p> <pre><code>import asyncio\nfrom medium_converter import convert_article\n\nasync def main():\n    # Basic conversion\n    await convert_article(\n        url=\"https://medium.com/example-article\",\n        output_format=\"markdown\",\n        output_path=\"article.md\"\n    )\n\n    # With enhancement\n    await convert_article(\n        url=\"https://medium.com/example-article\",\n        output_format=\"pdf\",\n        output_path=\"article.pdf\",\n        enhance=True\n    )\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"getting-started/quickstart/#common-options","title":"Common Options","text":""},{"location":"getting-started/quickstart/#export-formats","title":"Export Formats","text":"<p>Medium Converter supports various export formats:</p> <ul> <li><code>markdown</code> (default): Converts to Markdown format</li> <li><code>pdf</code>: Generates a PDF document</li> <li><code>html</code>: Creates an HTML file</li> <li><code>latex</code>: Produces LaTeX source</li> <li><code>epub</code>: Creates an EPUB e-book</li> <li><code>docx</code>: Generates a Word document</li> </ul>"},{"location":"getting-started/quickstart/#access-paywalled-articles","title":"Access Paywalled Articles","text":"<p>Medium Converter can use your browser cookies to access articles behind the paywall:</p> <pre><code># Using command line\nmedium convert https://medium.com/example-article --use-cookies\n\n# Using Python\nawait convert_article(\n    url=\"https://medium.com/example-article\",\n    use_cookies=True\n)\n</code></pre>"},{"location":"getting-started/quickstart/#llm-enhancement","title":"LLM Enhancement","text":"<p>You can enhance the article content using LLMs:</p> <pre><code># Using command line\nmedium convert https://medium.com/example-article --enhance --llm-provider openai\n\n# Using Python\nawait convert_article(\n    url=\"https://medium.com/example-article\",\n    enhance=True,\n    llm_config={\n        \"provider\": \"openai\",\n        \"model\": \"gpt-3.5-turbo\"\n    }\n)\n</code></pre>"},{"location":"getting-started/quickstart/#next-steps","title":"Next Steps","text":"<ul> <li>Learn more about CLI usage</li> <li>Explore the Python API</li> <li>Understand authentication for paywalled articles</li> <li>Configure LLM enhancement</li> </ul>"},{"location":"user-guide/auth/","title":"Authentication","text":"<p>Medium Converter can access articles behind Medium's paywall by using authentication cookies from your browser.</p>"},{"location":"user-guide/auth/#browser-cookies","title":"Browser Cookies","text":"<p>By default, Medium Converter attempts to extract cookies from your browser to authenticate requests to Medium. This allows you to access articles that would normally require a Medium membership if you're already logged in.</p>"},{"location":"user-guide/auth/#supported-browsers","title":"Supported Browsers","text":"<p>Medium Converter supports extracting cookies from the following browsers:</p> <ul> <li>Chrome/Chromium</li> <li>Firefox</li> <li>Safari (macOS only)</li> <li>Edge</li> <li>Opera</li> <li>Brave</li> </ul>"},{"location":"user-guide/auth/#using-browser-cookies","title":"Using Browser Cookies","text":""},{"location":"user-guide/auth/#command-line","title":"Command Line","text":"<pre><code># Enabled by default\nmedium convert https://medium.com/example-article\n\n# Explicitly enable\nmedium convert https://medium.com/example-article --use-cookies\n\n# Disable\nmedium convert https://medium.com/example-article --no-cookies\n</code></pre>"},{"location":"user-guide/auth/#python-api","title":"Python API","text":"<pre><code>from medium_converter import convert_article\n\n# Enabled by default\nawait convert_article(\n    url=\"https://medium.com/example-article\",\n    output_format=\"markdown\"\n)\n\n# Explicitly enable\nawait convert_article(\n    url=\"https://medium.com/example-article\",\n    output_format=\"markdown\",\n    use_cookies=True\n)\n\n# Disable\nawait convert_article(\n    url=\"https://medium.com/example-article\",\n    output_format=\"markdown\",\n    use_cookies=False\n)\n</code></pre>"},{"location":"user-guide/auth/#manual-cookie-configuration","title":"Manual Cookie Configuration","text":"<p>If automatic cookie extraction doesn't work, you can manually specify cookies:</p>"},{"location":"user-guide/auth/#environment-variables","title":"Environment Variables","text":"<pre><code>export MEDIUM_SID=your_sid_cookie\nexport MEDIUM_UID=your_uid_cookie\n</code></pre>"},{"location":"user-guide/auth/#configuration-file","title":"Configuration File","text":"<p>In <code>~/.medium-converter/config.toml</code>:</p> <pre><code>[auth]\nsid = \"your_sid_cookie\"\nuid = \"your_uid_cookie\"\n</code></pre>"},{"location":"user-guide/auth/#python-api_1","title":"Python API","text":"<pre><code>from medium_converter import convert_article\nfrom medium_converter.core.auth import get_medium_cookies\n\n# Create a custom cookie dictionary\ncookies = {\n    \"sid\": \"your_sid_cookie\",\n    \"uid\": \"your_uid_cookie\"\n}\n\nawait convert_article(\n    url=\"https://medium.com/example-article\",\n    output_format=\"markdown\",\n    cookies=cookies\n)\n</code></pre>"},{"location":"user-guide/auth/#finding-your-cookies-manually","title":"Finding Your Cookies Manually","text":"<p>If you need to manually find your Medium cookies:</p> <ol> <li>Log in to Medium in your browser</li> <li>Open DevTools (F12 or Right-click &gt; Inspect)</li> <li>Go to the Application tab (Chrome) or Storage tab (Firefox)</li> <li>Select Cookies in the left sidebar</li> <li>Select the medium.com domain</li> <li>Look for <code>sid</code> and <code>uid</code> cookies</li> </ol>"},{"location":"user-guide/auth/#limitations","title":"Limitations","text":"<ul> <li>Cookie authentication only works if you have an active Medium membership</li> <li>Cookies expire after a certain period (usually a few weeks)</li> <li>Some browsers store cookies in an encrypted format that may not be accessible</li> <li>Corporate security policies might prevent accessing cookies</li> </ul>"},{"location":"user-guide/cli/","title":"Command Line Interface","text":"<p>Medium Converter provides a simple but powerful command-line interface (CLI).</p>"},{"location":"user-guide/cli/#basic-commands","title":"Basic Commands","text":""},{"location":"user-guide/cli/#convert-command","title":"Convert Command","text":"<p>The main functionality is provided by the <code>convert</code> command:</p> <pre><code>medium convert &lt;url&gt; [options]\n</code></pre>"},{"location":"user-guide/cli/#options","title":"Options","text":"Option Description <code>--format</code>, <code>-f</code> Output format (markdown, pdf, html, latex, epub, docx) <code>--output</code>, <code>-o</code> Output file path <code>--output-dir</code>, <code>-d</code> Output directory (auto-generates filename) <code>--enhance</code> Use LLM to enhance article content <code>--no-enhance</code> Disable LLM enhancement (default) <code>--use-cookies</code> Use browser cookies for authentication <code>--no-cookies</code> Disable browser cookie fetching <code>--llm-provider</code> LLM provider to use (openai, anthropic, google, mistral, local)"},{"location":"user-guide/cli/#examples","title":"Examples","text":"<pre><code># Basic conversion to Markdown\nmedium convert https://medium.com/example-article\n\n# Convert to PDF\nmedium convert https://medium.com/example-article -f pdf -o article.pdf\n\n# Convert with LLM enhancement using OpenAI\nmedium convert https://medium.com/example-article --enhance --llm-provider openai\n\n# Convert with browser cookies for paywall access\nmedium convert https://medium.com/example-article --use-cookies\n</code></pre>"},{"location":"user-guide/cli/#batch-command","title":"Batch Command","text":"<p>For converting multiple articles at once:</p> <pre><code>medium batch &lt;file&gt; [options]\n</code></pre> <p>The <code>file</code> should contain a list of Medium URLs, one per line.</p>"},{"location":"user-guide/cli/#options_1","title":"Options","text":"Option Description <code>--format</code>, <code>-f</code> Output format (markdown, pdf, html, latex, epub, docx) <code>--output-dir</code>, <code>-d</code> Output directory (required) <code>--enhance</code> Use LLM to enhance article content <code>--no-enhance</code> Disable LLM enhancement (default) <code>--concurrent</code>, <code>-c</code> Maximum number of concurrent downloads (default: 3) <code>--use-cookies</code> Use browser cookies for authentication <code>--no-cookies</code> Disable browser cookie fetching <code>--llm-provider</code> LLM provider to use (openai, anthropic, google, mistral, local)"},{"location":"user-guide/cli/#examples_1","title":"Examples","text":"<pre><code># Convert multiple articles\nmedium batch articles.txt -f pdf -d ./articles\n\n# Convert with enhancement and higher concurrency\nmedium batch articles.txt -f markdown -d ./articles --enhance -c 5\n</code></pre>"},{"location":"user-guide/cli/#config-command","title":"Config Command","text":"<p>Manage persistent configuration:</p> <pre><code>medium config &lt;action&gt; [key] [value]\n</code></pre>"},{"location":"user-guide/cli/#actions","title":"Actions","text":"Action Description <code>show</code> Display current configuration <code>set</code> Set a configuration value <code>get</code> Get a configuration value <code>reset</code> Reset configuration to defaults"},{"location":"user-guide/cli/#examples_2","title":"Examples","text":"<pre><code># Show current configuration\nmedium config show\n\n# Set default format\nmedium config set default_format pdf\n\n# Set LLM provider\nmedium config set llm.provider anthropic\n\n# Reset configuration\nmedium config reset\n</code></pre>"},{"location":"user-guide/cli/#global-options","title":"Global Options","text":"<p>These options work with all commands:</p> Option Description <code>--verbose</code>, <code>-v</code> Enable verbose output <code>--debug</code> Enable debug logging <code>--quiet</code>, <code>-q</code> Suppress all output except errors <code>--help</code>, <code>-h</code> Show help message <code>--version</code> Show version information"},{"location":"user-guide/cli/#environment-variables","title":"Environment Variables","text":"<p>The CLI respects the environment variables documented in the Configuration section.</p>"},{"location":"user-guide/python-api/","title":"Python API","text":"<p>Medium Converter provides both synchronous and asynchronous Python APIs for integration into your projects.</p>"},{"location":"user-guide/python-api/#high-level-functions","title":"High-Level Functions","text":""},{"location":"user-guide/python-api/#asynchronous-api","title":"Asynchronous API","text":"<p>The main asynchronous function for converting a single article:</p> <pre><code>import asyncio\nfrom medium_converter import convert_article\n\nasync def main():\n    await convert_article(\n        url=\"https://medium.com/example-article\",\n        output_format=\"markdown\",\n        output_path=\"article.md\",\n        enhance=False,\n        use_cookies=True,\n        llm_config=None,\n        export_options=None\n    )\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre> <p>For batch conversion of multiple articles:</p> <pre><code>import asyncio\nfrom medium_converter import batch_convert\n\nasync def main():\n    urls = [\n        \"https://medium.com/article1\",\n        \"https://medium.com/article2\",\n        \"https://medium.com/article3\",\n    ]\n\n    await batch_convert(\n        urls=urls,\n        output_format=\"markdown\",\n        output_dir=\"./articles\",\n        enhance=True,\n        use_cookies=True,\n        max_concurrent=3,\n        llm_config=None,\n        export_options=None\n    )\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"user-guide/python-api/#synchronous-api","title":"Synchronous API","text":"<p>For simpler use cases, synchronous versions are available:</p> <pre><code>from medium_converter import convert_article_sync\n\n# Convert a single article\nconvert_article_sync(\n    url=\"https://medium.com/example-article\",\n    output_format=\"markdown\",\n    output_path=\"article.md\",\n    enhance=False\n)\n</code></pre> <p>And for batch conversion:</p> <pre><code>from medium_converter import batch_convert_sync\n\nurls = [\n    \"https://medium.com/article1\",\n    \"https://medium.com/article2\",\n]\n\nbatch_convert_sync(\n    urls=urls,\n    output_format=\"pdf\",\n    output_dir=\"./articles\",\n    enhance=True\n)\n</code></pre>"},{"location":"user-guide/python-api/#function-parameters","title":"Function Parameters","text":""},{"location":"user-guide/python-api/#convert_article-convert_article_sync","title":"<code>convert_article</code> / <code>convert_article_sync</code>","text":"Parameter Type Description Default <code>url</code> <code>str</code> URL of the Medium article (Required) <code>output_format</code> <code>str</code> Export format (markdown, pdf, html, etc.) <code>\"markdown\"</code> <code>output_path</code> <code>str</code> Path to save the converted article <code>None</code> (auto-generated) <code>enhance</code> <code>bool</code> Use LLM to enhance content <code>False</code> <code>use_cookies</code> <code>bool</code> Use browser cookies for authentication <code>True</code> <code>llm_config</code> <code>LLMConfig</code> Configuration for LLM enhancement <code>None</code> <code>export_options</code> <code>dict</code> Format-specific export options <code>None</code>"},{"location":"user-guide/python-api/#batch_convert-batch_convert_sync","title":"<code>batch_convert</code> / <code>batch_convert_sync</code>","text":"Parameter Type Description Default <code>urls</code> <code>List[str]</code> List of Medium article URLs (Required) <code>output_format</code> <code>str</code> Export format (markdown, pdf, html, etc.) <code>\"markdown\"</code> <code>output_dir</code> <code>str</code> Directory to save the converted articles (Required) <code>enhance</code> <code>bool</code> Use LLM to enhance content <code>False</code> <code>use_cookies</code> <code>bool</code> Use browser cookies for authentication <code>True</code> <code>max_concurrent</code> <code>int</code> Maximum number of concurrent downloads <code>3</code> <code>llm_config</code> <code>LLMConfig</code> Configuration for LLM enhancement <code>None</code> <code>export_options</code> <code>dict</code> Format-specific export options <code>None</code>"},{"location":"user-guide/python-api/#advanced-usage","title":"Advanced Usage","text":""},{"location":"user-guide/python-api/#custom-pipeline","title":"Custom Pipeline","text":"<p>For more control, you can use the individual components:</p> <pre><code>import asyncio\nfrom medium_converter.core.fetcher import fetch_article\nfrom medium_converter.core.parser import parse_article\nfrom medium_converter.core.auth import get_medium_cookies\nfrom medium_converter.llm.enhancer import enhance_article\nfrom medium_converter.llm.config import LLMConfig, LLMProvider\nfrom medium_converter.exporters.markdown import MarkdownExporter\n\nasync def main():\n    # Get authentication cookies\n    cookies = get_medium_cookies()\n\n    # Fetch article HTML\n    html = await fetch_article(\n        url=\"https://medium.com/example-article\",\n        cookies=cookies\n    )\n\n    # Parse article\n    article = parse_article(html)\n\n    # Set up LLM configuration\n    llm_config = LLMConfig(\n        provider=LLMProvider.OPENAI,\n        model=\"gpt-3.5-turbo\",\n        temperature=0.7\n    )\n\n    # Enhance article content\n    enhanced_article = await enhance_article(article, llm_config)\n\n    # Export to Markdown\n    exporter = MarkdownExporter()\n    md_content = exporter.export(enhanced_article, \"article.md\")\n\n    print(f\"Article exported to article.md\")\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"user-guide/python-api/#error-handling","title":"Error Handling","text":"<pre><code>import asyncio\nfrom medium_converter import convert_article\n\nasync def main():\n    try:\n        await convert_article(\n            url=\"https://medium.com/example-article\",\n            output_format=\"pdf\",\n            output_path=\"article.pdf\"\n        )\n        print(\"Conversion successful\")\n    except ValueError as e:\n        print(f\"Invalid input: {e}\")\n    except IOError as e:\n        print(f\"I/O error: {e}\")\n    except Exception as e:\n        print(f\"Unexpected error: {e}\")\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"user-guide/formats/markdown/","title":"Markdown Export","text":"<p>Markdown is the default export format for Medium Converter. This format preserves the content structure while creating a plain text file that's readable and can be further processed with other Markdown tools.</p>"},{"location":"user-guide/formats/markdown/#basic-usage","title":"Basic Usage","text":""},{"location":"user-guide/formats/markdown/#command-line","title":"Command Line","text":"<pre><code># Default format is Markdown\nmedium convert https://medium.com/example-article\n\n# Explicitly specify Markdown format\nmedium convert https://medium.com/example-article -f markdown -o article.md\n</code></pre>"},{"location":"user-guide/formats/markdown/#python-api","title":"Python API","text":"<pre><code>from medium_converter import convert_article\n\n# Using default format (markdown)\nawait convert_article(\n    url=\"https://medium.com/example-article\",\n    output_path=\"article.md\"\n)\n\n# Explicitly specify markdown format\nawait convert_article(\n    url=\"https://medium.com/example-article\",\n    output_format=\"markdown\",\n    output_path=\"article.md\"\n)\n</code></pre>"},{"location":"user-guide/formats/markdown/#customization-options","title":"Customization Options","text":"<p>You can customize the Markdown export with the following options:</p> Option Description Default <code>include_frontmatter</code> Add YAML frontmatter with metadata <code>True</code> <code>syntax_highlighting</code> Enable syntax highlighting for code blocks <code>True</code> <code>include_toc</code> Generate table of contents <code>False</code> <code>heading_style</code> Style for headings (atx or setext) <code>\"atx\"</code> <code>image_path</code> Path for downloaded images <code>\"images/\"</code> <code>download_images</code> Download and save images locally <code>False</code>"},{"location":"user-guide/formats/markdown/#command-line_1","title":"Command Line","text":"<pre><code>medium convert https://medium.com/example-article -f markdown \\\n  --option include_frontmatter=true \\\n  --option include_toc=true \\\n  --option download_images=true\n</code></pre>"},{"location":"user-guide/formats/markdown/#python-api_1","title":"Python API","text":"<pre><code>await convert_article(\n    url=\"https://medium.com/example-article\",\n    output_format=\"markdown\",\n    output_path=\"article.md\",\n    export_options={\n        \"include_frontmatter\": True,\n        \"include_toc\": True,\n        \"download_images\": True,\n        \"image_path\": \"assets/images/\",\n    }\n)\n</code></pre>"},{"location":"user-guide/formats/markdown/#output-format","title":"Output Format","text":"<p>The Markdown output follows these conventions:</p> <ol> <li>Article title as main heading (H1)</li> <li>Optional YAML frontmatter with metadata</li> <li>Optional table of contents</li> <li>Article sections with appropriate heading levels</li> <li>Images with alt text when available</li> <li>Code blocks with language specification</li> <li>Tables as GitHub-style Markdown tables</li> <li>Mathematical formulas using KaTeX syntax</li> </ol>"},{"location":"user-guide/formats/markdown/#example-output","title":"Example Output","text":"<pre><code>---\ntitle: \"Example Article Title\"\nauthor: \"Author Name\"\ndate: \"2023-05-20\"\nurl: \"https://medium.com/example-article\"\ntags: [\"programming\", \"python\", \"tutorial\"]\nreading_time: 5\n---\n\n# Example Article Title\n\nBy Author Name | May 20, 2023 | 5 min read\n\n## Introduction\n\nThis is a paragraph of text from the article. It might contain *emphasized* or **bold** text.\n\n![Image description](images/image1.jpg)\n\n### Code Example\n\n```python\ndef hello_world():\n    print(\"Hello, world!\")\n</code></pre>"},{"location":"user-guide/formats/markdown/#conclusion","title":"Conclusion","text":"<p>This is the conclusion paragraph. ```</p>"},{"location":"user-guide/formats/markdown/#using-with-other-tools","title":"Using with Other Tools","text":"<p>Markdown output is compatible with:</p> <ul> <li>Static site generators (Jekyll, Hugo, Gatsby)</li> <li>Documentation tools (MkDocs, VuePress, Docusaurus)</li> <li>Note-taking applications (Obsidian, Notion)</li> <li>Version control systems for easy diffing</li> <li>Markdown editors and processors (Pandoc)</li> </ul>"},{"location":"user-guide/formats/other-formats/","title":"Other Export Formats","text":"<p>In addition to Markdown and PDF, Medium Converter supports several other export formats.</p>"},{"location":"user-guide/formats/other-formats/#html","title":"HTML","text":""},{"location":"user-guide/formats/other-formats/#installation","title":"Installation","text":"<pre><code>pip install medium-converter[html]\n</code></pre>"},{"location":"user-guide/formats/other-formats/#usage","title":"Usage","text":"<pre><code># Command Line\nmedium convert https://medium.com/example-article -f html -o article.html\n\n# Python API\nawait convert_article(\n    url=\"https://medium.com/example-article\",\n    output_format=\"html\",\n    output_path=\"article.html\"\n)\n</code></pre>"},{"location":"user-guide/formats/other-formats/#options","title":"Options","text":"Option Description Default <code>template</code> HTML template to use <code>\"default\"</code> <code>include_css</code> Include CSS in the HTML file <code>True</code> <code>include_images</code> Download and include images <code>True</code> <code>syntax_highlighting</code> Enable syntax highlighting <code>True</code> <code>make_responsive</code> Make the HTML responsive <code>True</code>"},{"location":"user-guide/formats/other-formats/#latex","title":"LaTeX","text":""},{"location":"user-guide/formats/other-formats/#installation_1","title":"Installation","text":"<pre><code>pip install medium-converter[latex]\n</code></pre>"},{"location":"user-guide/formats/other-formats/#usage_1","title":"Usage","text":"<pre><code># Command Line\nmedium convert https://medium.com/example-article -f latex -o article.tex\n\n# Python API\nawait convert_article(\n    url=\"https://medium.com/example-article\",\n    output_format=\"latex\",\n    output_path=\"article.tex\"\n)\n</code></pre>"},{"location":"user-guide/formats/other-formats/#options_1","title":"Options","text":"Option Description Default <code>document_class</code> LaTeX document class <code>\"article\"</code> <code>include_preamble</code> Include LaTeX preamble <code>True</code> <code>include_packages</code> Include required packages <code>True</code> <code>use_listings</code> Use listings package for code <code>True</code>"},{"location":"user-guide/formats/other-formats/#epub","title":"EPUB","text":""},{"location":"user-guide/formats/other-formats/#installation_2","title":"Installation","text":"<pre><code>pip install medium-converter[epub]\n</code></pre>"},{"location":"user-guide/formats/other-formats/#usage_2","title":"Usage","text":"<pre><code># Command Line\nmedium convert https://medium.com/example-article -f epub -o article.epub\n\n# Python API\nawait convert_article(\n    url=\"https://medium.com/example-article\",\n    output_format=\"epub\",\n    output_path=\"article.epub\"\n)\n</code></pre>"},{"location":"user-guide/formats/other-formats/#options_2","title":"Options","text":"Option Description Default <code>cover_image</code> Path to cover image <code>None</code> <code>language</code> EPUB language code <code>\"en\"</code> <code>publisher</code> Publisher name <code>\"Medium Converter\"</code> <code>include_toc</code> Include table of contents <code>True</code>"},{"location":"user-guide/formats/other-formats/#docx-word","title":"DOCX (Word)","text":""},{"location":"user-guide/formats/other-formats/#installation_3","title":"Installation","text":"<pre><code>pip install medium-converter[word]\n</code></pre>"},{"location":"user-guide/formats/other-formats/#usage_3","title":"Usage","text":"<pre><code># Command Line\nmedium convert https://medium.com/example-article -f docx -o article.docx\n\n# Python API\nawait convert_article(\n    url=\"https://medium.com/example-article\",\n    output_format=\"docx\",\n    output_path=\"article.docx\"\n)\n</code></pre>"},{"location":"user-guide/formats/other-formats/#options_3","title":"Options","text":"Option Description Default <code>template</code> Path to DOCX template <code>None</code> <code>heading_style</code> Style for headings <code>\"Heading {level}\"</code> <code>paragraph_style</code> Style for paragraphs <code>\"Normal\"</code> <code>code_style</code> Style for code blocks <code>\"Code\"</code>"},{"location":"user-guide/formats/other-formats/#plain-text","title":"Plain Text","text":""},{"location":"user-guide/formats/other-formats/#usage_4","title":"Usage","text":"<pre><code># Command Line\nmedium convert https://medium.com/example-article -f text -o article.txt\n\n# Python API\nawait convert_article(\n    url=\"https://medium.com/example-article\",\n    output_format=\"text\",\n    output_path=\"article.txt\"\n)\n</code></pre>"},{"location":"user-guide/formats/other-formats/#options_4","title":"Options","text":"Option Description Default <code>width</code> Line width in characters <code>80</code> <code>include_metadata</code> Include article metadata <code>True</code> <code>indent_code</code> Indent code blocks <code>True</code>"},{"location":"user-guide/formats/other-formats/#custom-formats","title":"Custom Formats","text":"<p>You can create custom exporters by extending the <code>BaseExporter</code> class:</p> <pre><code>from medium_converter.exporters.base import BaseExporter\nfrom medium_converter.core.models import Article\nfrom typing import Optional, Union, TextIO, BinaryIO\n\nclass MyCustomExporter(BaseExporter):\n    def export(self, article: Article, output: Optional[Union[str, TextIO, BinaryIO]] = None) -&gt; str:\n        # Implement your custom export logic here\n        content = f\"Title: {article.title}\\nAuthor: {article.author}\\n\\n\"\n\n        # Add content blocks\n        for item in article.content:\n            # Process content based on type\n            content += process_item(item) + \"\\n\\n\"\n\n        # Write to output if specified\n        if output:\n            if isinstance(output, str):\n                with open(output, 'w') as f:\n                    f.write(content)\n            else:\n                output.write(content)\n\n        return content\n</code></pre> <p>Then register your exporter:</p> <pre><code>from medium_converter.exporters import register_exporter\n\nregister_exporter(\"custom\", MyCustomExporter)\n</code></pre> <p>Now you can use your custom format:</p> <pre><code>await convert_article(\n    url=\"https://medium.com/example-article\",\n    output_format=\"custom\",\n    output_path=\"article.custom\"\n)\n</code></pre>"},{"location":"user-guide/formats/pdf/","title":"PDF Export","text":"<p>Medium Converter can export articles to PDF, creating professionally formatted documents that are ready for printing or sharing.</p>"},{"location":"user-guide/formats/pdf/#installation","title":"Installation","text":"<p>PDF export requires additional dependencies:</p> <pre><code>pip install medium-converter[pdf]\n</code></pre> <p>Or if installing everything:</p> <pre><code>pip install medium-converter[all]\n</code></pre>"},{"location":"user-guide/formats/pdf/#basic-usage","title":"Basic Usage","text":""},{"location":"user-guide/formats/pdf/#command-line","title":"Command Line","text":"<pre><code># Convert to PDF\nmedium convert https://medium.com/example-article -f pdf -o article.pdf\n</code></pre>"},{"location":"user-guide/formats/pdf/#python-api","title":"Python API","text":"<pre><code>from medium_converter import convert_article\n\nawait convert_article(\n    url=\"https://medium.com/example-article\",\n    output_format=\"pdf\",\n    output_path=\"article.pdf\"\n)\n</code></pre>"},{"location":"user-guide/formats/pdf/#customization-options","title":"Customization Options","text":"<p>PDF export supports various customization options:</p> Option Description Default <code>page_size</code> Page size (A4, Letter, etc.) <code>\"A4\"</code> <code>font_size</code> Base font size in points <code>11</code> <code>font_family</code> Font family for text <code>\"Helvetica\"</code> <code>margins</code> Page margins in inches <code>{\"top\": 1, \"right\": 1, \"bottom\": 1, \"left\": 1}</code> <code>include_toc</code> Generate table of contents <code>True</code> <code>include_cover</code> Generate cover page <code>True</code> <code>include_images</code> Include images in PDF <code>True</code> <code>syntax_highlighting</code> Enable syntax highlighting for code <code>True</code> <code>header_text</code> Custom header text <code>None</code> <code>footer_text</code> Custom footer text <code>None</code> <code>page_numbers</code> Include page numbers <code>True</code>"},{"location":"user-guide/formats/pdf/#command-line_1","title":"Command Line","text":"<pre><code>medium convert https://medium.com/example-article -f pdf \\\n  --option page_size=Letter \\\n  --option font_size=12 \\\n  --option include_cover=true \\\n  --option header_text=\"Medium Article\" \\\n  --option footer_text=\"Generated with Medium Converter\"\n</code></pre>"},{"location":"user-guide/formats/pdf/#python-api_1","title":"Python API","text":"<pre><code>await convert_article(\n    url=\"https://medium.com/example-article\",\n    output_format=\"pdf\",\n    output_path=\"article.pdf\",\n    export_options={\n        \"page_size\": \"Letter\",\n        \"font_size\": 12,\n        \"font_family\": \"Times-Roman\",\n        \"include_cover\": True,\n        \"header_text\": \"Medium Article\",\n        \"footer_text\": \"Generated with Medium Converter\"\n    }\n)\n</code></pre>"},{"location":"user-guide/formats/pdf/#custom-styling","title":"Custom Styling","text":"<p>For advanced styling, you can provide a CSS stylesheet:</p> <pre><code>custom_css = \"\"\"\n@page {\n    @top-center {\n        content: \"Custom Header\";\n    }\n    @bottom-center {\n        content: \"Page \" counter(page);\n    }\n}\n\nh1 {\n    color: #0066cc;\n    font-size: 24pt;\n}\n\npre {\n    background-color: #f5f5f5;\n    padding: 10pt;\n    border-radius: 5pt;\n}\n\"\"\"\n\nawait convert_article(\n    url=\"https://medium.com/example-article\",\n    output_format=\"pdf\",\n    output_path=\"article.pdf\",\n    export_options={\n        \"custom_stylesheet\": custom_css\n    }\n)\n</code></pre> <p>Or provide a stylesheet file:</p> <pre><code>await convert_article(\n    url=\"https://medium.com/example-article\",\n    output_format=\"pdf\",\n    output_path=\"article.pdf\",\n    export_options={\n        \"stylesheet_path\": \"path/to/custom.css\"\n    }\n)\n</code></pre>"},{"location":"user-guide/formats/pdf/#pdf-features","title":"PDF Features","text":"<p>The PDF exporter provides several features:</p> <ol> <li>Cover Page: Title, author, date, and estimated reading time</li> <li>Table of Contents: Automatically generated TOC with page numbers</li> <li>Header and Footer: Customizable header and footer content</li> <li>Syntax Highlighting: Code blocks with syntax highlighting</li> <li>Hyperlinks: Active hyperlinks to websites and internal references</li> <li>Images: Embedded images with captions</li> <li>Math Rendering: LaTeX math formulas rendered properly</li> <li>Bookmarks: PDF bookmarks for easy navigation</li> </ol>"},{"location":"user-guide/formats/pdf/#implementation-details","title":"Implementation Details","text":"<p>Under the hood, Medium Converter uses ReportLab for PDF generation. The process involves:</p> <ol> <li>Parsing the article into a structured document</li> <li>Converting the content to ReportLab's flowable objects</li> <li>Applying styling and formatting</li> <li>Generating the PDF with proper layout</li> </ol> <p>For extremely complex layouts, consider using the LaTeX exporter and converting to PDF with a LaTeX processor.</p>"},{"location":"user-guide/llm/overview/","title":"LLM Enhancement Overview","text":"<p>Medium Converter includes an optional feature to enhance article content using Large Language Models (LLMs). This enhancement can improve readability, clarity, and grammar while preserving the original meaning.</p>"},{"location":"user-guide/llm/overview/#what-llm-enhancement-does","title":"What LLM Enhancement Does","text":"<p>When enabled, LLM enhancement:</p> <ol> <li>Fixes grammar and spelling errors</li> <li>Improves sentence structure and flow</li> <li>Makes technical explanations clearer</li> <li>Enhances overall readability</li> <li>Preserves the original meaning and intent</li> <li>Maintains the author's voice and style</li> </ol>"},{"location":"user-guide/llm/overview/#installation","title":"Installation","text":"<p>LLM enhancement requires additional dependencies:</p> <pre><code># Core LLM dependencies\npip install medium-converter[llm]\n\n# Provider-specific dependencies\npip install medium-converter[openai]  # For OpenAI models\npip install medium-converter[anthropic]  # For Anthropic Claude models\npip install medium-converter[google]  # For Google Gemini models\npip install medium-converter[mistral]  # For Mistral AI models\npip install medium-converter[local]  # For local models via llama-cpp\n\n# All LLM providers\npip install medium-converter[all-llm]\n</code></pre>"},{"location":"user-guide/llm/overview/#basic-usage","title":"Basic Usage","text":""},{"location":"user-guide/llm/overview/#command-line","title":"Command Line","text":"<pre><code># Enable enhancement with default provider (OpenAI if API key is set)\nmedium convert https://medium.com/example-article --enhance\n\n# Specify a provider\nmedium convert https://medium.com/example-article --enhance --llm-provider anthropic\n</code></pre>"},{"location":"user-guide/llm/overview/#python-api","title":"Python API","text":"<pre><code>from medium_converter import convert_article\n\n# Enable enhancement with default provider\nawait convert_article(\n    url=\"https://medium.com/example-article\",\n    output_format=\"markdown\",\n    output_path=\"article.md\",\n    enhance=True\n)\n\n# Specify a provider using LLMConfig\nfrom medium_converter.llm.config import LLMConfig, LLMProvider\n\nllm_config = LLMConfig(\n    provider=LLMProvider.ANTHROPIC,\n    model=\"claude-3-sonnet-20240229\",\n    temperature=0.7\n)\n\nawait convert_article(\n    url=\"https://medium.com/example-article\",\n    output_format=\"markdown\",\n    output_path=\"article.md\",\n    enhance=True,\n    llm_config=llm_config\n)\n</code></pre>"},{"location":"user-guide/llm/overview/#configuration","title":"Configuration","text":"<p>You can configure LLM enhancement using environment variables:</p> <pre><code># Provider selection\nexport MEDIUM_LLM_PROVIDER=openai  # or anthropic, google, mistral, local\n\n# API keys\nexport OPENAI_API_KEY=your_api_key\nexport ANTHROPIC_API_KEY=your_api_key\nexport GOOGLE_API_KEY=your_api_key\nexport MISTRAL_API_KEY=your_api_key\n\n# Model selection\nexport OPENAI_MODEL=gpt-4\nexport ANTHROPIC_MODEL=claude-3-opus-20240229\nexport GOOGLE_MODEL=gemini-pro\nexport MISTRAL_MODEL=mistral-large-latest\n\n# Parameters\nexport MEDIUM_LLM_TEMPERATURE=0.5\nexport MEDIUM_LLM_MAX_TOKENS=4000\n</code></pre>"},{"location":"user-guide/llm/overview/#how-it-works","title":"How It Works","text":"<p>LLM enhancement processes each content block in the article:</p> <ol> <li>Extracts the text content from the article</li> <li>Prepares prompts for the LLM with appropriate context</li> <li>Calls the LLM API with the prompt</li> <li>Replaces the original text with the enhanced version</li> <li>Preserves all formatting, images, and structure</li> </ol> <p>For example, this prompt template is used:</p> <pre><code>You are a world-class editor and writer. Your task is to enhance the following text \nfrom an article titled \"{article_title}\" while preserving its meaning and intent.\n\nTHE TEXT TO ENHANCE:\n{text}\n\nPlease improve this text by:\n1. Fixing any grammar or spelling errors\n2. Improving clarity and flow\n3. Making the language more engaging and precise\n4. Ensuring technical accuracy\n5. Keeping a consistent style and tone\n\nYOUR ENHANCED VERSION (respond with only the enhanced text, nothing else):\n</code></pre>"},{"location":"user-guide/llm/overview/#privacy-and-data-usage","title":"Privacy and Data Usage","text":"<p>When using LLM enhancement:</p> <ul> <li>Article content is sent to the LLM provider's API</li> <li>Your API key is used for authentication and billing</li> <li>Data handling is subject to the provider's privacy policy</li> <li>No article content is stored by Medium Converter</li> <li>For enhanced privacy, consider using local models</li> </ul>"},{"location":"user-guide/llm/overview/#limitations","title":"Limitations","text":"<p>LLM enhancement has some limitations:</p> <ul> <li>May occasionally alter meaning despite safeguards</li> <li>Quality depends on the LLM provider and model</li> <li>Can increase processing time significantly</li> <li>Requires API keys and may incur costs</li> <li>May have token limits for very long articles</li> </ul>"},{"location":"user-guide/llm/overview/#next-steps","title":"Next Steps","text":"<ul> <li>Learn about supported LLM providers</li> <li>Set up self-hosted LLMs</li> <li>Read the API reference for LLM enhancement</li> </ul>"},{"location":"user-guide/llm/providers/","title":"LLM Providers","text":"<p>Medium Converter supports various LLM providers for content enhancement. This page details each provider's setup and configuration.</p>"},{"location":"user-guide/llm/providers/#openai","title":"OpenAI","text":""},{"location":"user-guide/llm/providers/#installation","title":"Installation","text":"<pre><code>pip install medium-converter[openai]\n</code></pre>"},{"location":"user-guide/llm/providers/#configuration","title":"Configuration","text":"<pre><code># Environment variable\nexport OPENAI_API_KEY=your_api_key\nexport OPENAI_MODEL=gpt-4  # Optional, defaults to gpt-3.5-turbo\n</code></pre> <p>In Python:</p> <pre><code>from medium_converter import convert_article\nfrom medium_converter.llm.config import LLMConfig, LLMProvider\n\nllm_config = LLMConfig(\n    provider=LLMProvider.OPENAI,\n    model=\"gpt-4\",\n    api_key=\"your_api_key\",\n    temperature=0.7,\n    max_tokens=None  # Use model default\n)\n\nawait convert_article(\n    url=\"https://medium.com/example-article\",\n    enhance=True,\n    llm_config=llm_config\n)\n</code></pre>"},{"location":"user-guide/llm/providers/#available-models","title":"Available Models","text":"<ul> <li><code>gpt-3.5-turbo</code> (default)</li> <li><code>gpt-3.5-turbo-16k</code></li> <li><code>gpt-4</code></li> <li><code>gpt-4-turbo</code></li> <li><code>gpt-4-32k</code></li> </ul>"},{"location":"user-guide/llm/providers/#anthropic","title":"Anthropic","text":""},{"location":"user-guide/llm/providers/#installation_1","title":"Installation","text":"<pre><code>pip install medium-converter[anthropic]\n</code></pre>"},{"location":"user-guide/llm/providers/#configuration_1","title":"Configuration","text":"<pre><code># Environment variable\nexport ANTHROPIC_API_KEY=your_api_key\nexport ANTHROPIC_MODEL=claude-3-sonnet-20240229  # Optional\n</code></pre> <p>In Python:</p> <pre><code>from medium_converter import convert_article\nfrom medium_converter.llm.config import LLMConfig, LLMProvider\n\nllm_config = LLMConfig(\n    provider=LLMProvider.ANTHROPIC,\n    model=\"claude-3-opus-20240229\",\n    api_key=\"your_api_key\",\n    temperature=0.5\n)\n\nawait convert_article(\n    url=\"https://medium.com/example-article\",\n    enhance=True,\n    llm_config=llm_config\n)\n</code></pre>"},{"location":"user-guide/llm/providers/#available-models_1","title":"Available Models","text":"<ul> <li><code>claude-3-haiku-20240307</code> (default)</li> <li><code>claude-3-sonnet-20240229</code></li> <li><code>claude-3-opus-20240229</code></li> <li><code>claude-2.1</code></li> <li><code>claude-2.0</code></li> </ul>"},{"location":"user-guide/llm/providers/#google","title":"Google","text":""},{"location":"user-guide/llm/providers/#installation_2","title":"Installation","text":"<pre><code>pip install medium-converter[google]\n</code></pre>"},{"location":"user-guide/llm/providers/#configuration_2","title":"Configuration","text":"<pre><code># Environment variable\nexport GOOGLE_API_KEY=your_api_key\nexport GOOGLE_MODEL=gemini-pro  # Optional, this is the default\n</code></pre> <p>In Python:</p> <pre><code>from medium_converter import convert_article\nfrom medium_converter.llm.config import LLMConfig, LLMProvider\n\nllm_config = LLMConfig(\n    provider=LLMProvider.GOOGLE,\n    model=\"gemini-pro\",\n    api_key=\"your_api_key\",\n    temperature=0.4\n)\n\nawait convert_article(\n    url=\"https://medium.com/example-article\",\n    enhance=True,\n    llm_config=llm_config\n)\n</code></pre>"},{"location":"user-guide/llm/providers/#available-models_2","title":"Available Models","text":"<ul> <li><code>gemini-pro</code> (default)</li> <li><code>gemini-pro-vision</code></li> <li><code>gemini-1.5-pro</code></li> <li><code>gemini-1.5-flash</code></li> </ul>"},{"location":"user-guide/llm/providers/#mistral-ai","title":"Mistral AI","text":""},{"location":"user-guide/llm/providers/#installation_3","title":"Installation","text":"<pre><code>pip install medium-converter[mistral]\n</code></pre>"},{"location":"user-guide/llm/providers/#configuration_3","title":"Configuration","text":"<pre><code># Environment variable\nexport MISTRAL_API_KEY=your_api_key\nexport MISTRAL_MODEL=mistral-medium  # Optional, this is the default\n</code></pre> <p>In Python:</p> <pre><code>from medium_converter import convert_article\nfrom medium_converter.llm.config import LLMConfig, LLMProvider\n\nllm_config = LLMConfig(\n    provider=LLMProvider.MISTRAL,\n    model=\"mistral-large-latest\",\n    api_key=\"your_api_key\",\n    temperature=0.7\n)\n\nawait convert_article(\n    url=\"https://medium.com/example-article\",\n    enhance=True,\n    llm_config=llm_config\n)\n</code></pre>"},{"location":"user-guide/llm/providers/#available-models_3","title":"Available Models","text":"<ul> <li><code>mistral-medium</code> (default)</li> <li><code>mistral-small-latest</code></li> <li><code>mistral-large-latest</code></li> <li><code>open-mixtral-8x7b</code></li> <li><code>open-mistral-7b</code></li> </ul>"},{"location":"user-guide/llm/providers/#using-litellm","title":"Using LiteLLM","text":"<p>Medium Converter uses LiteLLM under the hood, which provides a unified interface to multiple LLM providers. This allows you to use any provider supported by LiteLLM by specifying the appropriate model name.</p>"},{"location":"user-guide/llm/providers/#installation_4","title":"Installation","text":"<pre><code>pip install medium-converter[llm]\n</code></pre>"},{"location":"user-guide/llm/providers/#configuration_4","title":"Configuration","text":"<p>In Python:</p> <pre><code>from medium_converter import convert_article\nfrom medium_converter.llm.config import LLMConfig\n\n# Custom provider via LiteLLM\nllm_config = LLMConfig(\n    model=\"replicate/llama-2-70b-chat:58d078176e02c219e11eb4da5a02a7830a283b14cf8f94537af893ccff5ee781\",\n    api_key=\"your_replicate_api_key\",\n    extra_params={\n        \"provider\": \"replicate\"\n    }\n)\n\nawait convert_article(\n    url=\"https://medium.com/example-article\",\n    enhance=True,\n    llm_config=llm_config\n)\n</code></pre>"},{"location":"user-guide/llm/providers/#provider-comparison","title":"Provider Comparison","text":"Provider Strengths Limitations Cost OpenAI High quality, wide adoption Higher cost, proprietary $0.50-$30/million tokens Anthropic Great for long content, accurate Higher cost, proprietary $3-$15/million tokens Google Competitive pricing, reliable Limited model options $0.25-$1.50/million tokens Mistral Open weights options, competitive Newer, less tested $1-$8/million tokens Local LLMs Privacy, no API costs Requires hardware, lower quality Free (compute costs)"},{"location":"user-guide/llm/self-hosted/","title":"Self-Hosted LLMs","text":"<p>Medium Converter can integrate with self-hosted LLMs, giving you privacy, cost savings, and control over the enhancement process.</p>"},{"location":"user-guide/llm/self-hosted/#local-llm-setup","title":"Local LLM Setup","text":""},{"location":"user-guide/llm/self-hosted/#installation","title":"Installation","text":"<pre><code>pip install medium-converter[local]\n</code></pre> <p>This installs the <code>llama-cpp-python</code> package which allows running various local LLMs.</p>"},{"location":"user-guide/llm/self-hosted/#using-local-models","title":"Using Local Models","text":""},{"location":"user-guide/llm/self-hosted/#command-line","title":"Command Line","text":"<pre><code># Use local LLM for enhancement\nmedium convert https://medium.com/example-article --enhance --llm-provider local \\\n  --option llm.model_path=\"path/to/model.gguf\"\n</code></pre>"},{"location":"user-guide/llm/self-hosted/#python-api","title":"Python API","text":"<pre><code>from medium_converter import convert_article\nfrom medium_converter.llm.config import LLMConfig, LLMProvider\n\nllm_config = LLMConfig(\n    provider=LLMProvider.LOCAL,\n    extra_params={\n        \"model_path\": \"path/to/model.gguf\",\n        \"n_ctx\": 4096,\n        \"n_batch\": 512\n    }\n)\n\nawait convert_article(\n    url=\"https://medium.com/example-article\",\n    enhance=True,\n    llm_config=llm_config\n)\n</code></pre>"},{"location":"user-guide/llm/self-hosted/#recommended-models","title":"Recommended Models","text":"<p>The following models work well with Medium Converter:</p> <ol> <li>Mistral-7B-Instruct - Good balance of quality and performance</li> <li>TheBloke/Mistral-7B-Instruct-v0.2-GGUF</li> <li> <p>Recommended quantization: Q4_K_M</p> </li> <li> <p>Llama-2-7b-chat - Good text enhancement capabilities</p> </li> <li>TheBloke/Llama-2-7B-Chat-GGUF</li> <li> <p>Recommended quantization: Q4_K_M</p> </li> <li> <p>Phi-2 - Lightweight model for basic enhancements</p> </li> <li>TheBloke/phi-2-GGUF</li> <li>Recommended quantization: Q4_0</li> </ol>"},{"location":"user-guide/llm/self-hosted/#configuration-options","title":"Configuration Options","text":"Option Description Default <code>model_path</code> Path to the model file (.gguf) Required <code>n_ctx</code> Context window size 2048 <code>n_batch</code> Batch size for prompt processing 512 <code>n_gpu_layers</code> Number of layers to offload to GPU 0 <code>temperature</code> Randomness of generations 0.7 <code>repeat_penalty</code> Penalty for repeating tokens 1.1 <code>top_p</code> Nucleus sampling parameter 0.9 <code>top_k</code> Limit vocabulary to top K options 40"},{"location":"user-guide/llm/self-hosted/#server-integration","title":"Server Integration","text":"<p>Medium Converter can use local LLMs running on a server with compatible APIs.</p>"},{"location":"user-guide/llm/self-hosted/#using-lm-studio","title":"Using LM Studio","text":"<ol> <li>Download and install LM Studio</li> <li>Load a model of your choice</li> <li>Start the local server (OpenAI API compatible)</li> <li>Configure Medium Converter:</li> </ol> <pre><code>from medium_converter import convert_article\nfrom medium_converter.llm.config import LLMConfig, LLMProvider\n\nllm_config = LLMConfig(\n    provider=LLMProvider.OPENAI,  # Uses OpenAI-compatible API\n    model=\"local-model\",  # Model name doesn't matter\n    api_base=\"http://localhost:1234/v1\",  # LM Studio server URL\n    api_key=\"lm-studio\",  # Any string works\n)\n\nawait convert_article(\n    url=\"https://medium.com/example-article\",\n    enhance=True,\n    llm_config=llm_config\n)\n</code></pre>"},{"location":"user-guide/llm/self-hosted/#using-ollama","title":"Using Ollama","text":"<ol> <li>Install Ollama</li> <li>Pull a model: <code>ollama pull mistral</code></li> <li>Start Ollama</li> <li>Configure Medium Converter:</li> </ol> <pre><code>from medium_converter import convert_article\nfrom medium_converter.llm.config import LLMConfig\n\nllm_config = LLMConfig(\n    model=\"ollama/mistral\",  # Must prefix with ollama/\n    extra_params={\n        \"api_base\": \"http://localhost:11434\"\n    }\n)\n\nawait convert_article(\n    url=\"https://medium.com/example-article\",\n    enhance=True,\n    llm_config=llm_config\n)\n</code></pre>"},{"location":"user-guide/llm/self-hosted/#performance-considerations","title":"Performance Considerations","text":"<ul> <li>Hardware Requirements: Most 7B models require at least 8GB of RAM</li> <li>GPU Acceleration: Setting <code>n_gpu_layers</code> &gt; 0 can dramatically improve performance if you have a GPU</li> <li>Quantization: Lower precision (e.g., Q4_K_M) reduces memory requirements but may affect quality</li> <li>Context Length: Reducing <code>n_ctx</code> can save memory but limits the text length that can be processed at once</li> </ul>"},{"location":"user-guide/llm/self-hosted/#troubleshooting","title":"Troubleshooting","text":""},{"location":"user-guide/llm/self-hosted/#common-issues","title":"Common Issues","text":"<ol> <li>Out of Memory</li> <li>Try a smaller model or lower quantization (Q4 instead of Q8)</li> <li>Reduce the context length (<code>n_ctx</code>)</li> <li> <p>Process the article in smaller chunks</p> </li> <li> <p>Slow Performance</p> </li> <li>Enable GPU acceleration if available</li> <li>Increase batch size (<code>n_batch</code>) if you have sufficient memory</li> <li> <p>Use a smaller model</p> </li> <li> <p>Poor Quality Output</p> </li> <li>Try a larger or more recent model</li> <li>Adjust temperature (lower for more deterministic output)</li> <li>Fine-tune prompt templates (see the docs on customizing prompts)</li> </ol>"}]}